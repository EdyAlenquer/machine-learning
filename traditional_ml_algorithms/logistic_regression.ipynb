{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "    right_prediction = y_true == y_pred\n",
    "    accuracy = right_prediction.sum() / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,0] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    recall = right_prediction.sum() / len(array)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,1] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    precision = right_prediction.sum() / len(array)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    precision_score = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "\n",
    "    f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.mean = data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (scaled_data * self.std) + self.mean\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_cross_validation(data, n_folds=10, shuffle=True, random_state=12894):\n",
    "    indexes = np.arange(data.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "    slices = np.array_split(indexes, n_folds)\n",
    "    all_elements = np.hstack(slices)   \n",
    "    \n",
    "    splits = []\n",
    "    for i in range(n_folds):\n",
    "        train_idx = all_elements[~np.isin(all_elements, slices[i])]\n",
    "        test_idx = slices[i]\n",
    "\n",
    "        splits.append((train_idx, test_idx))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size_perc, random_seed=264852):\n",
    "    N = data.shape[0]\n",
    "    train_size = int(train_size_perc * N)\n",
    "\n",
    "    indexes = np.arange(0, N, 1)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(indexes, train_size, replace=False)\n",
    "    test_idx = np.delete(indexes, train_idx)\n",
    "\n",
    "    train_data = data[train_idx]\n",
    "    test_data = data[test_idx]\n",
    "\n",
    "    X_train = train_data[:,:-1]\n",
    "    y_train = train_data[:,[-1]]\n",
    "\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,[-1]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cv_and_get_metrics(classifier, cv_splits, X_train, y_train, X_test, title='Classifier', scaler=None):\n",
    "\n",
    "    X_train = X_train.copy()\n",
    "    y_train = y_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    train_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    valid_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        # Spliting data\n",
    "        X_train_cv = X_train[train_idx, :]\n",
    "        y_train_cv = y_train[train_idx, :]\n",
    "        X_val_cv = X_train[val_idx, :]\n",
    "        y_val_cv = y_train[val_idx, :]\n",
    "\n",
    "        # Scaling if have scaler argument\n",
    "        if scaler is not None:\n",
    "            X_train_cv = scaler.fit_transform(X_train_cv)\n",
    "            X_val_cv = scaler.transform(X_val_cv)\n",
    "\n",
    "        # Training Model\n",
    "        classifier.fit(X_train_cv, y_train_cv.ravel())\n",
    "\n",
    "        # Predictions\n",
    "        y_train_cv_pred = classifier.predict(X_train_cv)\n",
    "        y_val_cv_pred = classifier.predict(X_val_cv)\n",
    "\n",
    "        # Storing metrics\n",
    "        train_metrics['accuracy'].append(accuracy(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['recall'].append(recall(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['precision'].append(precision(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['f1_score'].append(f1_score(y_train_cv, y_train_cv_pred))\n",
    "\n",
    "        valid_metrics['accuracy'].append(accuracy(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['recall'].append(recall(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['precision'].append(precision(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['f1_score'].append(f1_score(y_val_cv, y_val_cv_pred))\n",
    "\n",
    "\n",
    "    # Reporting results\n",
    "    print('#' + f'{title}'.center(60, '-') + '#')\n",
    "    print('\\n--->\\tTraining Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['accuracy']), \n",
    "        np.std(train_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['recall']), \n",
    "        np.std(train_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['precision']), \n",
    "        np.std(train_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['f1_score']), \n",
    "        np.std(train_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tValidation Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['accuracy']), \n",
    "        np.std(valid_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['recall']), \n",
    "        np.std(valid_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['precision']), \n",
    "        np.std(valid_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['f1_score']), \n",
    "        np.std(valid_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tTest Metrics')\n",
    "\n",
    "    if scaler is not None:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "    print('Accuracy:     \\t{0:.4f}'.format(accuracy(y_test, y_test_pred)))\n",
    "    print('Recall:     \\t{0:.4f}'.format(recall(y_test, y_test_pred)))\n",
    "    print('Precision:     \\t{0:.4f}'.format(precision(y_test, y_test_pred)))\n",
    "    print('F1 Score:     \\t{0:.4f}'.format(f1_score(y_test, y_test_pred)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8, random_seed=5482) #64825\n",
    "\n",
    "cv_splits = kfolds_cross_validation(\n",
    "    data=X_train,\n",
    "    n_folds=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(y, y_pred_proba):\n",
    "    cost_1 = y.T @ np.log(y_pred_proba)\n",
    "    cost_0 = (1-y).T @ np.log(1-y_pred_proba)\n",
    "    j = -(1/len(y)) * (cost_1 + cost_0)\n",
    "    return j.ravel()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha, \n",
    "        n_iterations\n",
    "    ):        \n",
    "        self.alpha = alpha        \n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize(self, X, y, random_state=654812):\n",
    "        rnd_state = np.random.RandomState(random_state)\n",
    "        self.X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        self.y = y.reshape(-1, 1)\n",
    "\n",
    "        self.w = np.zeros((np.shape(X)[1]+1,1))\n",
    "        # self.w = rnd_state.uniform(0, 1, self.X.shape[1]).reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, y, random_state=654812):\n",
    "        \n",
    "        if len(y.shape)==1:\n",
    "            y = y.reshape(-1, 1)\n",
    "            \n",
    "        self.initialize(X, y, random_state)\n",
    "        self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        self.loss_by_iteration = []\n",
    "        for i in range(self.n_iterations):\n",
    "            actual_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            e = (self.y - actual_y_pred_proba) \n",
    "            \n",
    "            grad = ((1/len(self.y)) * self.alpha * (e.T @ self.X))\n",
    "            grad = grad.reshape(-1, 1)\n",
    "            self.w = self.w + grad \n",
    "            \n",
    "\n",
    "            new_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            self.loss_by_iteration.append(\n",
    "                cross_entropy_loss(self.y, new_y_pred_proba)\n",
    "            )\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        return predict_proba\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        predict_label = np.where(predict_proba>threshold, 1, 0)\n",
    "        return predict_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------My Logistic Regression-------------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9768 | Accuracy Std:   \t0.0027\n",
      "Recall Mean:     \t0.9924 | Recall Std:       \t0.0021\n",
      "Precision Mean:     \t0.9704 | Precision Std:   \t0.0030\n",
      "F1 Score Mean:     \t0.9813 | F1 Score Std:   \t0.0022\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9757 | Accuracy Std:   \t0.0232\n",
      "Recall Mean:     \t0.9924 | Recall Std:       \t0.0153\n",
      "Precision Mean:     \t0.9694 | Precision Std:   \t0.0309\n",
      "F1 Score Mean:     \t0.9805 | F1 Score Std:   \t0.0190\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t1.0000\n",
      "Recall:     \t1.0000\n",
      "Precision:     \t1.0000\n",
      "F1 Score:     \t1.0000\n"
     ]
    }
   ],
   "source": [
    "my_reg_log = MyLogisticRegression(alpha=0.001, n_iterations=10000)\n",
    "do_cv_and_get_metrics(\n",
    "    classifier=my_reg_log, \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    scaler=StandardScaler(),\n",
    "    title='My Logistic Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26470bf2ca0>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(my_reg_log.loss_by_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------Sklearn Logistic Regression-----------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9861 | Accuracy Std:   \t0.0027\n",
      "Recall Mean:     \t0.9952 | Recall Std:       \t0.0039\n",
      "Precision Mean:     \t0.9823 | Precision Std:   \t0.0019\n",
      "F1 Score Mean:     \t0.9887 | F1 Score Std:   \t0.0022\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9735 | Accuracy Std:   \t0.0217\n",
      "Recall Mean:     \t0.9848 | Recall Std:       \t0.0306\n",
      "Precision Mean:     \t0.9729 | Precision Std:   \t0.0245\n",
      "F1 Score Mean:     \t0.9784 | F1 Score Std:   \t0.0193\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9912\n",
      "Recall:     \t0.9872\n",
      "Precision:     \t1.0000\n",
      "F1 Score:     \t0.9935\n"
     ]
    }
   ],
   "source": [
    "# TO COMPARE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg_log = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "do_cv_and_get_metrics(\n",
    "    classifier=reg_log, \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    scaler=scaler,\n",
    "    title='Sklearn Logistic Regression'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d84fc3ab72c8387ddb373470e784917d8b759f8763a65d23fac12a2e8075760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
