{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 4\n",
    "## Neural Networks\n",
    "\n",
    "Aluno: Francisco Edyvalberty Alenquer Cordeiro \\\n",
    "MatrÃ­cula: 518659\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "    right_prediction = y_true == y_pred\n",
    "    accuracy = right_prediction.sum() / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,0] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    recall = right_prediction.sum() / len(array)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,1] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    precision = right_prediction.sum() / len(array)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    precision_score = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "\n",
    "    f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "def get_mse(y_real, y_pred):\n",
    "    return np.mean((y_real - y_pred)**2)\n",
    "\n",
    "def get_rmse(y_real, y_pred):\n",
    "    return np.sqrt(get_mse(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.maximum = data.max(axis=0)\n",
    "        self.minimum = data.min(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (self.maximum - self.minimum) * scaled_data + self.minimum\n",
    "        return original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.mean = data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        original_data = (scaled_data * self.std) + self.mean\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_folds(data, n_folds=10, shuffle=True, random_state=12894):\n",
    "    indexes = np.arange(data.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "    slices = np.array_split(indexes, n_folds)\n",
    "    all_elements = np.hstack(slices)   \n",
    "    \n",
    "    splits = []\n",
    "    for i in range(n_folds):\n",
    "        train_idx = all_elements[~np.isin(all_elements, slices[i])]\n",
    "        test_idx = slices[i]\n",
    "\n",
    "        splits.append((train_idx, test_idx))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_size_perc, random_seed=264852):\n",
    "    \n",
    "    y = y.reshape(-1, 1)\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    train_size = int(train_size_perc * N)\n",
    "\n",
    "    indexes = np.arange(0, N, 1)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(indexes, train_size, replace=False)\n",
    "    test_idx = np.delete(indexes, train_idx)\n",
    "\n",
    "    X_train = X[train_idx, :]\n",
    "    y_train = y[train_idx, :]\n",
    "    X_test = X[test_idx, :]\n",
    "    y_test = y[test_idx, :]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Cross Validation and Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cv_and_get_metrics(classifier, cv_splits, X_train, y_train, X_test, title='Classifier', scaler=None):\n",
    "\n",
    "    X_train = X_train.copy()\n",
    "    y_train = y_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    train_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    valid_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "    # Reporting results\n",
    "    print('#' + f'{title}'.center(60, '-') + '#')\n",
    "\n",
    "    print('\\n---> Validation Folds Metrics')\n",
    "    print('Fold\\tAccuracy\\tRecall\\t\\tPrecision\\tF1-Score')\n",
    "    count_fold = 1\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        # Spliting data\n",
    "        X_train_cv = X_train[train_idx, :]\n",
    "        y_train_cv = y_train[train_idx, :]\n",
    "        X_val_cv = X_train[val_idx, :]\n",
    "        y_val_cv = y_train[val_idx, :]\n",
    "\n",
    "        # Scaling if have scaler argument\n",
    "        if scaler is not None:\n",
    "            X_train_cv = scaler.fit_transform(X_train_cv)\n",
    "            X_val_cv = scaler.transform(X_val_cv)\n",
    "\n",
    "        # Training Model\n",
    "        classifier.fit(X_train_cv, y_train_cv.ravel())\n",
    "\n",
    "        # Predictions\n",
    "        y_train_cv_pred = classifier.predict(X_train_cv)\n",
    "        y_val_cv_pred = classifier.predict(X_val_cv)\n",
    "\n",
    "        # Storing metrics\n",
    "        train_metrics['accuracy'].append(accuracy(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['recall'].append(recall(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['precision'].append(precision(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['f1_score'].append(f1_score(y_train_cv, y_train_cv_pred))\n",
    "\n",
    "        valid_metrics['accuracy'].append(accuracy(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['recall'].append(recall(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['precision'].append(precision(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['f1_score'].append(f1_score(y_val_cv, y_val_cv_pred))\n",
    "\n",
    "        print('{0:.0f}\\t{1:.4f}  \\t{2:.4f}\\t\\t{3:.4f}   \\t{4:.4f}'.format(\n",
    "                count_fold,\n",
    "                valid_metrics['accuracy'][-1], \n",
    "                valid_metrics['recall'][-1],\n",
    "                valid_metrics['precision'][-1],\n",
    "                valid_metrics['f1_score'][-1]\n",
    "            )\n",
    "        )\n",
    "        count_fold+=1\n",
    "\n",
    "\n",
    "    print('\\n--->\\tTraining Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['accuracy']), \n",
    "        np.std(train_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['recall']), \n",
    "        np.std(train_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['precision']), \n",
    "        np.std(train_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['f1_score']), \n",
    "        np.std(train_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tValidation Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['accuracy']), \n",
    "        np.std(valid_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['recall']), \n",
    "        np.std(valid_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['precision']), \n",
    "        np.std(valid_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['f1_score']), \n",
    "        np.std(valid_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tTest Metrics')\n",
    "\n",
    "    if scaler is not None:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "    print('Accuracy:     \\t{0:.4f}'.format(accuracy(y_test, y_test_pred)))\n",
    "    print('Recall:     \\t{0:.4f}'.format(recall(y_test, y_test_pred)))\n",
    "    print('Precision:     \\t{0:.4f}'.format(precision(y_test, y_test_pred)))\n",
    "    print('F1 Score:     \\t{0:.4f}'.format(f1_score(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - MLP (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1030, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 540.  ,    0.  ,    0.  ,  162.  ,    2.5 , 1040.  ,  676.  ,\n",
       "          28.  ,   79.99],\n",
       "       [ 540.  ,    0.  ,    0.  ,  162.  ,    2.5 , 1055.  ,  676.  ,\n",
       "          28.  ,   61.89],\n",
       "       [ 332.5 ,  142.5 ,    0.  ,  228.  ,    0.  ,  932.  ,  594.  ,\n",
       "         270.  ,   40.27]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/concrete.csv', delimiter=',')\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print('Shape:', data.shape)\n",
    "data[:3, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows by Split\n",
      "X_train: 618 (60.0%)\n",
      "X_test:  206 (20.0%)\n",
      "X_val:   206 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, 0.8, random_seed=466852\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, 0.75, random_seed=654824\n",
    ")\n",
    "\n",
    "print('Number of Rows by Split')\n",
    "print('X_train: {} ({}%)'.format(X_train.shape[0], X_train.shape[0]/data.shape[0]*100))\n",
    "print('X_test:  {} ({}%)'.format(X_test.shape[0], X_test.shape[0]/data.shape[0]*100))\n",
    "print('X_val:   {} ({}%)'.format(X_val.shape[0], X_val.shape[0]/data.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    @staticmethod\n",
    "    def get_value(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_derivative(x):\n",
    "        return Sigmoid.get_value(x) - Sigmoid.get_value(x)**2\n",
    "\n",
    "class ReLU():\n",
    "    @staticmethod\n",
    "    def get_value(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_derivative(x):\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "\n",
    "class Identity():\n",
    "    @staticmethod\n",
    "    def get_value(x):\n",
    "        return np.ones(x.shape) * x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_derivative(x):\n",
    "        return np.ones(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Shapes\n",
    "$$\n",
    "H_i(hidden\\_weight) \\rArr (n\\_neurons(H_{i-1}), n\\_neurons(H_i))\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pesos Antes\n",
      "[array([[0. , 0. ],\n",
      "       [0.1, 0.4],\n",
      "       [0.8, 0.6]]), array([[0. ],\n",
      "       [0.3],\n",
      "       [0.9]])]\n",
      "\n",
      "Pesos DEPOIS\n",
      "[array([[0.        , 0.        ],\n",
      "       [0.09907093, 0.39713992],\n",
      "       [0.79761096, 0.59264552]]), array([[0.        ],\n",
      "       [0.27232597],\n",
      "       [0.87299836]])]\n"
     ]
    }
   ],
   "source": [
    "# FUNCIONANDO PARA 1 EXEMPLO\n",
    "class MyMLP():\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        self.fitted = False\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.n_hidden = []\n",
    "        self.weights = []\n",
    "        self.activation_functions = [Identity(), Sigmoid()]\n",
    "        self.layer_inputs = []\n",
    "        self.layer_outputs = []\n",
    "        self.hidden_activation_derivatives = []\n",
    "        self.deltas = []\n",
    "\n",
    "    def get_n_neurons_of_last_layer(self):\n",
    "        if len(self.weights) == 0:\n",
    "            return self.n_inputs\n",
    "        else:\n",
    "            return len(self.weights[-1])\n",
    "\n",
    "    def add_hidden_layer(self, n_neurons, activation_function):\n",
    "        self.n_hidden.append(n_neurons)\n",
    "        self.activation_functions = self.activation_functions[:-1] \\\n",
    "            + [activation_function] \\\n",
    "            + [self.activation_functions[-1]]\n",
    "\n",
    "    def initialize_weights(self, random_state=8776123):\n",
    "        self.weights = []\n",
    "\n",
    "        seed = np.random.RandomState(random_state)\n",
    "        self.layers = [self.n_inputs] + self.n_hidden + [self.n_outputs]\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            # Initialization strategies\n",
    "            if type(self.activation_functions[i]) == ReLU:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i]+1, self.layers[i+1])\n",
    "                ) * np.sqrt(2/self.layers[i])  \n",
    "                w[0, :] = 0.01\n",
    "            else:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i]+1, self.layers[i+1])\n",
    "                ) * np.sqrt(1/self.layers[i])\n",
    "                w[0, :] = 0\n",
    "\n",
    "\n",
    "            # self.weights.append(w)\n",
    "        self.weights.append(np.array([\n",
    "            [0, 0], \n",
    "            [0.1, 0.4],\n",
    "            [0.8, 0.6]\n",
    "        ]))\n",
    "        self.weights.append(np.array([\n",
    "            [0], \n",
    "            [0.3],\n",
    "            [0.9]\n",
    "        ]))\n",
    "\n",
    "\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activated_values = X\n",
    "\n",
    "        self.layer_outputs = []\n",
    "        self.hidden_activation_derivatives = []\n",
    "\n",
    "        self.layer_outputs.append(activated_values)\n",
    "\n",
    "        for i, w in enumerate(self.weights):\n",
    "            # Insert first column with ones to multiply bias term\n",
    "            activated_values = np.hstack([np.ones((activated_values.shape[0], 1)), activated_values])\n",
    "            \n",
    "            activation_function = self.activation_functions[i+1]            \n",
    "            \n",
    "            # Calculating input of hidden layer\n",
    "            hidden_input = np.array(activated_values @ w)\n",
    "            if activation_function is not None:\n",
    "                # print('FORWARD', i)\n",
    "                # print(hidden_input)\n",
    "                # print(activation_function.get_value(hidden_input))\n",
    "                # print(activation_function)\n",
    "                activated_values = activation_function.get_value(hidden_input)\n",
    "            else:\n",
    "                activated_values = hidden_input\n",
    "                \n",
    "            self.layer_inputs.append(hidden_input)\n",
    "            self.layer_outputs.append(activated_values)\n",
    "        \n",
    "        self.layer_inputs = [X] + self.layer_inputs\n",
    "        return activated_values # Output\n",
    "\n",
    "\n",
    "    def back_propagation(self, error, alpha=1):\n",
    "\n",
    "        # calcular os deltas\n",
    "        last_layers = True\n",
    "        for i in range(len(self.activation_functions)-1, 0, -1):\n",
    "\n",
    "            act_function = self.activation_functions[i]\n",
    "            layer_inputs = self.layer_inputs[i]\n",
    "\n",
    "            if last_layers:\n",
    "                calc_i = error * act_function.get_derivative(layer_inputs)\n",
    "                self.deltas = [calc_i] + self.deltas\n",
    "                # print(self.deltas)\n",
    "                last_layers=False\n",
    "            else:\n",
    "                weights = self.weights[i][1:]\n",
    "                \n",
    "                # print('weights')\n",
    "                # print(weights.shape)\n",
    "                # print(weights)\n",
    "                # print('delta')\n",
    "                # print(self.deltas[0].shape)\n",
    "                # print(self.deltas[0])\n",
    "                # print('act_function')\n",
    "                # print(act_function.get_derivative(layer_inputs).T.shape)\n",
    "                # print(act_function.get_derivative(layer_inputs).T)\n",
    "                \n",
    "                calc_i = weights @ self.deltas[0] * act_function.get_derivative(layer_inputs).T\n",
    "                self.deltas = [calc_i] + self.deltas\n",
    "                # calc_i = error * act_function.get_derivative(layer_inputs)\n",
    "\n",
    "        # print('\\n\\n\\n----------PESOS\\n\\n\\n')\n",
    "        print('\\nPesos Antes')\n",
    "        print(self.weights)\n",
    "        for i in range(len(self.weights)):\n",
    "            # print('\\n\\n', i, '\\n\\n')\n",
    "            \n",
    "            # print(self.deltas[i])\n",
    "            # print(self.layer_outputs[i])\n",
    "            # print(self.deltas[i] @ self.layer_outputs[i])\n",
    "            # print('\\nTESTE\\n')\n",
    "            # print(self.weights[i][1:])\n",
    "            # print(gradient.T)\n",
    "            gradient = self.deltas[i] @ self.layer_outputs[i]\n",
    "            self.weights[i][1:, :] = self.weights[i][1:, :] - alpha * gradient.T\n",
    "\n",
    "            # print(i)  \n",
    "            # print(self.layer_inputs[i])\n",
    "        print('\\nPesos DEPOIS')\n",
    "        print(self.weights)\n",
    "\n",
    "\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "my_mlp = MyMLP(n_inputs=2, n_outputs=2)\n",
    "my_mlp.add_hidden_layer(n_neurons=2, activation_function=Sigmoid())\n",
    "# my_mlp.add_hidden_layer(n_neurons=2, activation_function=ReLU())\n",
    "\n",
    "my_mlp.initialize_weights()\n",
    "\n",
    "X = np.array([[0.35, 0.9]])\n",
    "y = np.array([[0.5]])\n",
    "\n",
    "y_pred = my_mlp.forward_propagation(X)\n",
    "error = y_pred - y\n",
    "\n",
    "my_mlp.back_propagation(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.21125633 -0.13177053 -0.24346945  0.29552883 -0.19150205\n",
      "  -0.25735021 -0.91155395 -0.26770572]\n",
      " [-0.47958908  0.48037115 -1.03552811 -0.26139674 -0.16657067 -0.52291482\n",
      "  -0.04704427  0.08008185 -0.22819911]\n",
      " [ 0.20667829 -0.47789413  0.22744415  0.28878475  0.40091788 -0.51051799\n",
      "   0.41193154 -0.17761967 -0.27852947]\n",
      " [ 0.06823243  0.39012196 -0.54897127 -0.12270746  0.15263795  0.04614792\n",
      "  -0.70509532 -0.14365739  0.82325983]]\n",
      "[[ 0.50902878  0.1871123  -1.20537613 -0.51350225  0.14349613]]\n",
      "MSE Epoch 0: 16.264069872365884\n",
      "MSE Epoch 10: 8.51995763097486\n",
      "MSE Epoch 20: 8.44066002728783\n",
      "MSE Epoch 30: 8.39638601725746\n",
      "MSE Epoch 40: 8.361230997102966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2351e0e03d0>]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyMLP_v1():\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, verbose=False):\n",
    "        self.fitted = False\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_hidden = []\n",
    "        self.activation_functions = [Identity(), Identity()]\n",
    "        self.deltas = []\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def add_hidden_layer(self, n_neurons, activation_function):\n",
    "        self.n_hidden.append(n_neurons)\n",
    "        self.activation_functions = self.activation_functions[:-1] \\\n",
    "            + [activation_function] \\\n",
    "            + [self.activation_functions[-1]]\n",
    "\n",
    "    def initialize_weights(self, random_state=8776123):\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "\n",
    "        seed = np.random.RandomState(random_state)\n",
    "        self.layers = [self.n_inputs] + self.n_hidden + [self.n_outputs]\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            # Initialization strategies\n",
    "            if type(self.activation_functions[i]) == ReLU:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i+1], self.layers[i])\n",
    "                ) * np.sqrt(2/self.layers[i])  \n",
    "                b = 0.01\n",
    "            else:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i+1], self.layers[i])\n",
    "                ) * np.sqrt(1/self.layers[i])\n",
    "                b = 0\n",
    "\n",
    "            self.weights.append(w)\n",
    "            self.bias.append(b)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activated_values = X\n",
    "\n",
    "        self.layer_inputs = []\n",
    "        self.layer_outputs = []\n",
    "\n",
    "        self.layer_outputs.append(activated_values)\n",
    "\n",
    "        for i, w in enumerate(self.weights):\n",
    "            activation_function = self.activation_functions[i+1]            \n",
    "            \n",
    "            # Calculating input of next layer\n",
    "            hidden_input = np.array(activated_values @ w.T + self.bias[i])\n",
    "            \n",
    "            # Passing values through the activation function of next layer\n",
    "            activated_values = activation_function.get_value(hidden_input)\n",
    "            \n",
    "            self.layer_inputs.append(hidden_input)\n",
    "            self.layer_outputs.append(activated_values)\n",
    "        \n",
    "        self.layer_inputs = [X] + self.layer_inputs\n",
    "        return activated_values # Output\n",
    "\n",
    "\n",
    "    def back_propagation(self, error, alpha=0.1):\n",
    "        # calcular os deltas\n",
    "        output_layer = True\n",
    "        self.deltas = []\n",
    "        for i in range(len(self.activation_functions)-1, 0, -1):\n",
    "            act_function = self.activation_functions[i]\n",
    "            layer_inputs = self.layer_inputs[i]\n",
    "            if output_layer:\n",
    "                delta_i = error * act_function.get_derivative(layer_inputs)\n",
    "                self.deltas = [delta_i] + self.deltas\n",
    "                output_layer=False\n",
    "            else:\n",
    "                weights = self.weights[i]\n",
    "                \n",
    "                if self.verbose == True:\n",
    "                    print(f'------ ITERAÃÃO {i} ------')\n",
    "                    print('\\nweights')\n",
    "                    print(weights.shape)\n",
    "                    print(weights)\n",
    "                    print('\\ndelta')\n",
    "                    print(self.deltas[0].shape)\n",
    "                    print(self.deltas[0])\n",
    "                    print('\\nact_function')\n",
    "                    print(act_function.get_derivative(layer_inputs).shape)\n",
    "                    print(act_function.get_derivative(layer_inputs))\n",
    "\n",
    "                delta_i = act_function.get_derivative(layer_inputs) \\\n",
    "                    * (self.deltas[0] @ weights)\n",
    "                self.deltas = [delta_i] + self.deltas\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            gradient = self.deltas[i].T @ self.layer_outputs[i]            \n",
    "            self.weights[i] = self.weights[i] - alpha * gradient\n",
    "            # self.bias[i] = self.bias[i] - alpha * np.sum(self.deltas[i], axis=0, keepdims=True)\n",
    "            # print(self.bias[i])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        activated_values = X\n",
    "\n",
    "        for i, w in enumerate(self.weights):\n",
    "            activation_function = self.activation_functions[i+1]           \n",
    "            \n",
    "            # Calculating input of hidden layer\n",
    "            hidden_input = np.array(activated_values @ w.T + self.bias[i])\n",
    "            activated_values = activation_function.get_value(hidden_input)\n",
    "        \n",
    "        self.layer_inputs = [X] + self.layer_inputs\n",
    "        return activated_values\n",
    "\n",
    "my_mlp_ant = MyMLP_v1(n_inputs=8, n_outputs=1, verbose=False)\n",
    "my_mlp_ant.add_hidden_layer(n_neurons=4, activation_function=ReLU())\n",
    "# my_mlp_ant.add_hidden_layer(n_neurons=2, activation_function=ReLU())\n",
    "\n",
    "my_mlp_ant.initialize_weights(65421)\n",
    "\n",
    "cost_function_curve = []\n",
    "\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    mse = 0\n",
    "    count = 0\n",
    "    for input, output in zip(X_train_scaled, y_train_scaled):\n",
    "        input_reshaped = input.reshape(1, -1)\n",
    "        output_reshaped = output.reshape(1, -1)        \n",
    "        y_pred = my_mlp_ant.forward_propagation(input_reshaped)\n",
    "        error = y_pred - output_reshaped\n",
    "        my_mlp_ant.back_propagation(error, 0.1)\n",
    "\n",
    "        output = y_scaler.inverse_transform(output)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "        mse+=get_rmse(output, y_pred)\n",
    "        count+=1\n",
    "    if i % 10 == 0:\n",
    "        cost_function_curve.append(mse/count)\n",
    "        print(f'MSE Epoch {i}:', mse/count)\n",
    "\n",
    "# for i in range(epochs):\n",
    " \n",
    "#     y_pred = my_mlp_ant.forward_propagation(X_train_scaled[:3])\n",
    "#     error = y_pred[:3] - y_train_scaled[:3]\n",
    "#     my_mlp_ant.back_propagation(error, 0.01)\n",
    "\n",
    "\n",
    "#     y_pred = y_scaler.inverse_transform(y_pred)\n",
    "#     mse=get_rmse(y_train[:3], y_pred)\n",
    "\n",
    "#     cost_function_curve.append(mse)\n",
    "    # print(f'MSE Epoch {i}:', mse)\n",
    "\n",
    "\n",
    "plt.plot(cost_function_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.259557525987374"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "y_test_pred = my_mlp.predict(X_test_scaled)\n",
    "\n",
    "y_test_pred = y_scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "mse = get_rmse(\n",
    "    y_test,\n",
    "    y_test_pred\n",
    ")\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP_v2():\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, learning_rate=0.01, verbose=False):\n",
    "        self.fitted = False\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_hidden = []\n",
    "        self.activation_functions = [Identity(), Identity()]\n",
    "        self.deltas = []\n",
    "        self.verbose=verbose\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def add_hidden_layer(self, n_neurons, activation_function):\n",
    "        self.n_hidden.append(n_neurons)\n",
    "        self.activation_functions = self.activation_functions[:-1] \\\n",
    "            + [activation_function] \\\n",
    "            + [self.activation_functions[-1]]\n",
    "\n",
    "    def initialize_weights(self, random_state=None):\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "\n",
    "        if random_state is None:\n",
    "            seed = np.random.RandomState()\n",
    "        else:\n",
    "            seed = np.random.RandomState(random_state)\n",
    "\n",
    "        self.layers = [self.n_inputs] + self.n_hidden + [self.n_outputs]\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            # Initialization strategies\n",
    "            if type(self.activation_functions[i]) == ReLU:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i+1], self.layers[i])\n",
    "                ) * np.sqrt(2/self.layers[i])  \n",
    "                w = np.hstack([np.ones((self.layers[i+1], 1))*0.1, w])\n",
    "            else:\n",
    "                w = seed.normal(\n",
    "                    size = (self.layers[i+1], self.layers[i])\n",
    "                ) * np.sqrt(1/self.layers[i])\n",
    "                w = np.hstack([np.zeros((self.layers[i+1], 1))*0.1, w])               \n",
    "\n",
    "            self.weights.append(w)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        input = np.hstack(\n",
    "            [np.ones((X.shape[0],1)), X]\n",
    "        )\n",
    "\n",
    "        self.layer_inputs = []\n",
    "        self.layer_outputs = []\n",
    "\n",
    "        self.layer_inputs.append(input)\n",
    "        self.layer_outputs.append(input)\n",
    "        \n",
    "        # Calculating input of next layer\n",
    "        for i, w in enumerate(self.weights):\n",
    "            activation_function = self.activation_functions[i+1]            \n",
    "            \n",
    "            self.layer_inputs.append(input)\n",
    "\n",
    "            # Calculating input of next layer\n",
    "            output = np.array(input @ w.T)\n",
    "\n",
    "            # Passing values through the activation function of next layer\n",
    "            activated_output = activation_function.get_value(output)\n",
    "            \n",
    "            if i < len(self.weights)-1:\n",
    "                activated_output = np.hstack(\n",
    "                    [np.ones((X.shape[0],1)), activated_output]\n",
    "                )\n",
    "            self.layer_outputs.append(activated_output)\n",
    "            input = activated_output\n",
    "\n",
    "        return activated_output # Output\n",
    "\n",
    "\n",
    "    def back_propagation(self, error, learning_rate):\n",
    "        # calcular os deltas\n",
    "        output_layer = True\n",
    "        self.deltas = []\n",
    "        for i in range(len(self.activation_functions)-1, 0, -1):\n",
    "            act_function = self.activation_functions[i]\n",
    "            \n",
    "            if output_layer:\n",
    "                layer_inputs = self.layer_outputs[i]\n",
    "                delta_i = error * act_function.get_derivative(layer_inputs)\n",
    "                self.deltas = [delta_i] + self.deltas\n",
    "                output_layer=False\n",
    "            else:\n",
    "                layer_inputs = self.layer_outputs[i][:, 1:]\n",
    "                weights = self.weights[i][:, 1:]\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f'------ ITERAÃÃO {i} ------')\n",
    "                    print('\\nweights')\n",
    "                    print(weights.shape)\n",
    "                    print(weights)\n",
    "                    print('\\ndelta')\n",
    "                    print(self.deltas[0].shape)\n",
    "                    print(self.deltas[0])\n",
    "                    print('\\nact_function')\n",
    "                    print(act_function.get_derivative(layer_inputs).shape)\n",
    "                    print(act_function.get_derivative(layer_inputs))\n",
    "\n",
    "                delta_i = act_function.get_derivative(layer_inputs) \\\n",
    "                    * (self.deltas[0] @ weights)\n",
    "                self.deltas = [delta_i] + self.deltas\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            gradient = self.deltas[i].T @ self.layer_outputs[i]\n",
    "            self.weights[i] = self.weights[i] - learning_rate * gradient\n",
    "\n",
    "\n",
    "    def get_minibatches(self, X, y, batch_size):\n",
    "        init_index=0\n",
    "        batches = []\n",
    "\n",
    "        for final_index in range(batch_size, X.shape[0]+batch_size, batch_size):\n",
    "            \n",
    "            X_minibatch = X[init_index:final_index]\n",
    "            y_minibatch = y[init_index:final_index]\n",
    "\n",
    "            if X_minibatch.shape[0] < batch_size:\n",
    "                n_missing_rows = batch_size - X_minibatch.shape[0]\n",
    "                X_minibatch = np.vstack([X_minibatch, X[0:n_missing_rows]])\n",
    "                y_minibatch = np.vstack([y_minibatch, y[0:n_missing_rows]])\n",
    "\n",
    "            init_index = final_index\n",
    "            batches.append((X_minibatch, y_minibatch))\n",
    "        \n",
    "        return batches\n",
    "\n",
    "\n",
    "    def fit(self, X, y, valid_set=None, epochs=100, batch_size=32):\n",
    "        \n",
    "        self.initialize_weights()\n",
    "        \n",
    "        self.loss_function_curve = []\n",
    "        self.loss_function_curve_val = []\n",
    "\n",
    "        for i, epochs in enumerate(range(epochs)):\n",
    "            loss_function = 0\n",
    "            val_loss_function = 0\n",
    "            count = 0\n",
    "            batches = self.get_minibatches(X, y, batch_size)\n",
    "            \n",
    "            for input, output in batches:\n",
    "                y_pred = self.forward_propagation(input)\n",
    "                \n",
    "                if valid_set is not None:\n",
    "                    X_val, y_val = valid_set[0], valid_set[1]\n",
    "                    y_val_pred = self.predict(X_val)\n",
    "                    val_loss_function+=get_mse(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "                error = y_pred - output\n",
    "                self.back_propagation(error, self.learning_rate)\n",
    "                loss_function+=get_mse(output, y_pred)\n",
    "                count+=1\n",
    "                \n",
    "            self.loss_function_curve.append(loss_function/count)\n",
    "            \n",
    "            \n",
    "            if valid_set is not None:\n",
    "                self.loss_function_curve_val.append(val_loss_function/count)\n",
    "                if self.verbose:\n",
    "                    print('Epoch {} -> Loss Function: Train {:.6f} | Valid {:.6f}'.format(\n",
    "                            i,\n",
    "                            loss_function/count,\n",
    "                            val_loss_function/count\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(f'Epoch {i} | Loss Function: ', loss_function/count)\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(self.loss_function_curve, label='Train')\n",
    "\n",
    "        if len(self.loss_function_curve_val)>0:\n",
    "            plt.plot(self.loss_function_curve_val, label='Validation')\n",
    "        \n",
    "        plt.title('Learning Curves', fontsize=18)\n",
    "        plt.legend()\n",
    "\n",
    "    def predict(self, X):\n",
    "        input = np.hstack(\n",
    "            [np.ones((X.shape[0],1)), X]\n",
    "        )\n",
    "\n",
    "        for i, w in enumerate(self.weights):\n",
    "            activation_function = self.activation_functions[i+1]            \n",
    "            \n",
    "            self.layer_inputs.append(input)\n",
    "\n",
    "            # Calculating input of next layer\n",
    "            output = np.array(input @ w.T)\n",
    "\n",
    "            # Passing values through the activation function of next layer\n",
    "            activated_output = activation_function.get_value(output)\n",
    "            \n",
    "            if i < len(self.weights)-1:\n",
    "                activated_output = np.hstack(\n",
    "                    [np.ones((X.shape[0],1)), activated_output]\n",
    "                )\n",
    "            input = activated_output\n",
    "\n",
    "        return activated_output\n",
    "\n",
    "my_mlp = MyMLP_v2(n_inputs=8, n_outputs=1, verbose=False)\n",
    "my_mlp.add_hidden_layer(n_neurons=4, activation_function=ReLU())\n",
    "# my_mlp.add_hidden_layer(n_neurons=2, activation_function=ReLU())\n",
    "\n",
    "\n",
    "\n",
    "# cost_function_curve = []\n",
    "\n",
    "# epochs = 100\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     mse = 0\n",
    "#     count = 0\n",
    "#     for input, output in zip(X_train_scaled, y_train_scaled):\n",
    "#         input_reshaped = input.reshape(1, -1)\n",
    "#         output_reshaped = output.reshape(1, -1)        \n",
    "#         y_pred = my_mlp.forward_propagation(input_reshaped)\n",
    "#         error = y_pred - output_reshaped\n",
    "#         my_mlp.back_propagation(error, 0.1)\n",
    "\n",
    "#         # output = y_scaler.inverse_transform(output)\n",
    "#         # y_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "#         mse+=get_rmse(output, y_pred)\n",
    "#         count+=1\n",
    "    \n",
    "#     cost_function_curve.append(mse/count)\n",
    "    # print(f'MSE Epoch {i}:', mse/count)\n",
    "\n",
    "# for i in range(epochs):\n",
    " \n",
    "#     y_pred = my_mlp.forward_propagation(X_train_scaled)\n",
    "#     error = y_pred - y_train_scaled\n",
    "#     my_mlp.back_propagation(error, 0.001)\n",
    "\n",
    "\n",
    "#     # y_pred = y_scaler.inverse_transform(y_pred)\n",
    "#     mse=get_mse(y_train_scaled, y_pred)\n",
    "\n",
    "#     cost_function_curve.append(mse)\n",
    "#     # if i % 10 == 0:\n",
    "#     #     print(f'MSE Epoch {i}:', mse)\n",
    "\n",
    "\n",
    "# plt.plot(cost_function_curve)\n",
    "\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "# y_test_scaled = y_scaler.transform(y_test)\n",
    "# y_test_pred = my_mlp.predict(X_test_scaled)\n",
    "\n",
    "# # y_test_pred = y_scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# y_train_pred = my_mlp.predict(X_train_scaled)\n",
    "# mse_train = get_mse(y_train_scaled, y_train_pred)\n",
    "\n",
    "# mse_test = get_mse(y_test_scaled, y_test_pred)\n",
    "\n",
    "# print('MSE Train:', mse_train)\n",
    "# print('MSE Test:', mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "y_val_scaled = y_scaler.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- RESULTS ----\n",
      "MSE Train:\t 0.017993346342215184\n",
      "MSE Test:\t 0.019401915490144382\n",
      "MSE Validation:\t 0.019183216073926715\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAHmCAYAAABd+zCNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/UklEQVR4nO3de7xcdX3v/9dnZucCAQyXoJEgF40XLBIwIhW1oNgCWvHGEc5RQD0iFVo9trXgz1bb/vzV9mBr+VXhh0pFCyflUYulFEVEqfaCEhSRCNGURomkEEBCIJd9mc/vj7Vm75XJJHv27JCdxbyej8xjZtb6rrW+a83ae8873+/6rshMJEmSJOmprjHTFZAkSZKkXcHwI0mSJGkgGH4kSZIkDQTDjyRJkqSBYPiRJEmSNBAMP5IkSZIGguFHkrRLRMTqiLhlpushSRpchh9J2o1FxAkRkRHxOzNdl6eSiNgzIt4fEd+OiEciYiQiHoiIGyLinIgYmuk6SpJ2Pn+5S5J2lecBM35n7Yh4DvBPwHOBrwN/AjwEHAicBPw1cATwwZmqoyTpyWH4kSRNSUTMApqZuXkqy2XmliepSj2LiD2A64HDgTdn5t93FPnTiHgJ8JKduM2+jpckaeez25skPUVExOKI+GJErI2I4fIam/8dEfM6yj0/Ij4dESsiYkNEbIyI2yPi3V3W+dGy290LI+LPI2INsBk4ruwelhHxqoj4nYj4j4jYEhE/joizu6xrm2t+2tPKOv1TWZ/1EfF3EfGMLut4UUR8LSKeiIiHI+LKiDigrMfnezhM/5OiBeoTXYIPAJl5W2Z+urLNruuu7P8JPRyv4yPi5xHxvW7bjIj3lMu9oTJtTkR8qPycNkfEoxHxjxFxdMeyUXbhu7M8fo9FxMqI+FwZvCRJJVt+JOkpICJeDHwDeBT4/4CfA0cBv0XxxftXMnOkLH4C8EqKFpD/BOYBpwOXR8QBmfknXTZxFbAJ+ARF17W1wKHlvP8H2KPc7hbgN4DPR8SqzPzXHqp/EHALcC3wu2W93wPsA/xqZR8XA9+m+I+7S8p9PBX4Sg/baHtL+Xz5FJbpR+fxWlNO+92I+KXMvKuj/FkUXe/+CcZbi74KvAz4IvBXwNOAdwP/GhGvzMzl5bIfBv4I+EfgMmAMOAx4PTAHGEGSBBh+JOmp4gqKQPKSzNzQnhgRNwN/D/wP4PPl5C9m5mXVhSPiLyjC04URcXElKLU9CpyUmaOVZX65fDmn3O5wOf3vgHuBC4Bews9zgLdm5jWVdbeA90bE8zPznnLyxygC0csroeqvIuJvgaU9bAfgl4ANmXlvj+X79SjbHq8rKcLdWVSuJ4qIZ1OEnP+3ctwvoAipJ2fmjZWynwbuAi4u5wO8Ebg7M1/fUYcLd97uSNJTg93eJKnmIuJI4EXA1cCcshvYARFxAPAvwBNUWlAy84nKsnMjYn9gP+BrFOHi+V0288nqF/kOn24Hn3L9Pwd+DCzucRfurwaf0jfK5+eU9WxStPJ8t0tr0id63A4U+/fYFMr3a5vjlZkrgNuB/xER1b+/Z5XPV1amvQ24B7i94/OcDdwEvLy8fglgPXBQRLz8ydgRSXoqMfxIUv29oHz+Q2Bdx+NBim5tT28Xjoi9IuLiiPgZRdesh8qyHyuL7NtlGz/ewfa7taI8DOzfY/23tzyVdSyg2I+VXcp2m7Y9jwF7T6F8v7Z3vL4APJNiVLm2twErMvP2yrQXUITQzs9zHfBOoAkcUJb9EMV1Rd8uryu6KiL+e0TM3lk7I0lPFXZ7k6T6i/L5ExTXiXTzi8rrq4HXUVz38i3gEWCUomXlf9H9P8Y27mD7Y5PUazLbW766jh2tayrDZ98FvDIiDt8JXd929Dd0e8fraooua2cBX4uIV1CMPPd7HeUC+CHwgR1sYx1AZv572XXu14ATy8d/Bz4cES/PzEcm2xFJGhSGH0mqv5+Uz2OZ+fUdFYyI+RTB54uZeV7HvJO6LrR7eJCi+97zuszr1k1ve75EMdjD/6RoMenFIxTdAjsdPoXtApCZD0XEDcAbI2IvihDUAv6mo+hPKFq7vpGZrR7W+zjFvn0JICLeC3wKeBfwv6daT0l6qrLbmyTV3/cpWjTOi4htvpBHxFBEtL+8t1tZoqPMQopAsFvKzDGKUd2OjYjjO2b/9hRW9VmKbnK/ExGndSsQES8uw0Pbj4Ffjog9K2X2Bd4xhe1WXQnsSdHd7XTgpsy8v6PMF4BnsJ2Wn4iodmM8oEuR9pDa3UKbJA0sW34kqR5eHRFzu0x/KDMvi4i3UwwScGdEXAGsoPiC/RzgTcBFwOczc0NEfA14W0RsAm4DDqEYWvo/6f06nZnwYYquXV+NiL+iGD76tRQtJNBD97fM3BgRr6MYUvrL5bG4ieIaowUUXcZ+DfizymJ/RdEy842I+CIwn2LI6Z9SBJSp+qdye39KMQDDlV3K/CXwGuB/R8SrKD7bx4BnAa+muMbnxLLs3RFxK/Ad4H5gIXAuMAws66N+kvSUZfiRpHo4uXx0Wglclpl3lDe/vIji/i7nARuA1RRDXN9cWeZtwMeBXwfOpuhi9X9R3A/mr5+c6k9fZq6MiFdSXDPzPooAcD1wPsWgCZt6XM+q8li9B3gzxb7vRdG9bTnFMbm6Uv6qiHgmxfDTf15u648ouqu9tI/9GI6I/1Ou7zHgy13KjETEa4H3Am+nGMwCinDzXbYOTJ+guF7rtyjuBfQgcCvwJ5n5g6nWT5KeyiJzKteJSpK0eylv8LocuCgzPz7T9ZEk7b685keSVBuVe9u03wcTNwy9adfXSJJUJ3Z7kyTVyR0R8Q2KYaDnUXTdewXwtx33yZEkaRt2e5Mk1UZE/BlF4DmY4j/w/hO4CvjTzByZybpJknZ/hh9JkiRJA8FrfiRJkiQNhFpd83PAAQfkoYceOtPVkCRJkrSbuv322x/KzAXd5tUq/Bx66KEsX758pqshSZIkaTcVET/d3jy7vUmSJEkaCIYfSZIkSQPB8CNJkiRpINTqmh9JkiSprkZGRlizZg2bN2+e6ao8JcydO5dFixYxa9asnpcx/EiSJEm7wJo1a9h777059NBDiYiZrk6tZSYPP/wwa9as4bDDDut5Obu9SZIkSbvA5s2b2X///Q0+O0FEsP/++0+5Fc3wI0mSJO0iBp+dp59jafiRJEmSnuIefvhhlixZwpIlS3jGM57BQQcdNP5+eHh4h8suX76c3/qt39pFNX1yec2PJEmS9BS3//77c8cddwDw0Y9+lL322ovf+Z3fGZ8/OjrK0FD3aLB06VKWLl26K6r5pLPlR5IkSRpA55xzDh/4wAc48cQT+b3f+z2++93v8rKXvYyjjz6al73sZaxcuRKAW265hde97nVAEZze+c53csIJJ3D44YdzySWXzOQuTJktP5IkSdIu9of/uIIf3f/YTl3nEc/ch4/8+guntMyPf/xjvv71r9NsNnnsscf41re+xdDQEF//+tf50Ic+xJe+9KVtlrnnnnv45je/yYYNG3je857Hb/zGb0xpuOmZZPiRJEmSBtTpp59Os9kEYP369Zx99tn85Cc/ISIYGRnpusxrX/ta5syZw5w5czjwwAN54IEHWLRo0a6sdt8MP5IkSdIuNtUWmifLvHnzxl///u//PieeeCLXXnstq1ev5oQTTui6zJw5c8ZfN5tNRkdHn+xq7jRe8yNJkiSJ9evXc9BBBwHw+c9/fmYr8yQx/EiSJEnigx/8IBdddBHHH388Y2NjM12dJ0Vk5kzXoWdLly7N5cuXz3Q1JEmSpCm7++67ecELXjDT1XhK6XZMI+L2zOw6NrctP30YGWuxftMIo2Otma6KJEmSpB4Zfvrw7Z+s46g//BordvLwhJIkSZKePIYfSZIkSQPB8CNJkiRpIPQUfiLi5IhYGRGrIuLCLvMjIi4p598ZEcdU5q2OiB9GxB0Rsbwy/aMR8fNy+h0RcerO2SVJkiRJ2takNzmNiCbwKeA1wBrgtoi4LjN/VCl2CrC4fLwUuLR8bjsxMx/qsvq/yMyL+628JEmSJPWql5afY4FVmXlvZg4Dy4DTOsqcBnwhC7cC8yNi4U6u626nPoOES5IkadCdcMIJ3HjjjVtN++QnP8l73/ve7ZZv32bm1FNP5dFHH92mzEc/+lEuvnjHbRlf/vKX+dGPJtpN/uAP/oCvf/3rU6z9ztFL+DkIuK/yfk05rdcyCXwtIm6PiHM7lrug7CZ3RUTsO4V6z6ggZroKkiRJ0pSceeaZLFu2bKtpy5Yt48wzz5x02RtuuIH58+f3td3O8PNHf/RHnHTSSX2ta7p6CT/dvul3NnrsqMzxmXkMRde48yPileX0S4FnA0uAtcAnum484tyIWB4Ry9etW9dDdSVJkiR1estb3sL111/Pli1bAFi9ejX3338/V199NUuXLuWFL3whH/nIR7oue+ihh/LQQ8VVLB/72Md43vOex0knncTKlSvHy3zmM5/hJS95CUcddRRvfvOb2bhxI//2b//Gddddx+/+7u+yZMkS/uM//oNzzjmHv/u7vwPg5ptv5uijj+bII4/kne9853jdDj30UD7ykY9wzDHHcOSRR3LPPffslGMw6TU/FK04B1feLwLu77VMZrafH4yIaym60X0rMx9oF46IzwDXd9t4Zl4OXA6wdOlSe5pJkiSp/r5yIfzXD3fuOp9xJJzy8e3O3n///Tn22GP56le/ymmnncayZct461vfykUXXcR+++3H2NgYr371q7nzzjt50Yte1HUdt99+O8uWLeP73/8+o6OjHHPMMbz4xS8G4E1vehPvfve7Afjwhz/M5z73OX7zN3+T17/+9bzuda/jLW95y1br2rx5M+eccw4333wzz33ucznrrLO49NJLef/73w/AAQccwPe+9z0+/elPc/HFF/PZz3522oeol5af24DFEXFYRMwGzgCu6yhzHXBWOerbccD6zFwbEfMiYm+AiJgH/CpwV/m+ek3QG9vTJUmSJD05ql3f2l3errnmGo455hiOPvpoVqxYsVUXtU7f/va3eeMb38iee+7JPvvsw+tf//rxeXfddReveMUrOPLII7nqqqtYsWLFDuuycuVKDjvsMJ773OcCcPbZZ/Otb31rfP6b3vQmAF784hezevXqfnd5K5O2/GTmaERcANwINIErMnNFRJxXzr8MuAE4FVgFbATeUS7+dODaiGhv6+rM/Go5788iYglF97jVwHt2yh5JkiRJu7sdtNA8md7whjfwgQ98gO9973ts2rSJfffdl4svvpjbbruNfffdl3POOYfNmzfvcB3ld/ttnHPOOXz5y1/mqKOO4vOf/zy33HLLDteTueNOXXPmzAGg2WwyOjq6w7K96uk+P5l5Q2Y+NzOfnZkfK6ddVgYfylHezi/nH5mZy8vp92bmUeXjhe1ly3lvL8u+KDNfn5lrd8oe7UKTfWCSJEnS7mSvvfbihBNO4J3vfCdnnnkmjz32GPPmzeNpT3saDzzwAF/5yld2uPwrX/lKrr32WjZt2sSGDRv4x3/8x/F5GzZsYOHChYyMjHDVVVeNT997773ZsGHDNut6/vOfz+rVq1m1ahUAX/ziF/mVX/mVnbSn3fVyzY86OdibJEmSaurMM8/kTW96E8uWLeP5z38+Rx99NC984Qs5/PDDOf7443e47DHHHMNb3/pWlixZwiGHHMIrXvGK8Xl//Md/zEtf+lIOOeQQjjzyyPHAc8YZZ/Dud7+bSy65ZHygA4C5c+fy13/915x++umMjo7ykpe8hPPOO+/J2elS1Kn1YunSpdkea3wmfXPlg7zjr2/j2ve+jKOfVZsRuiVJkjSD7r77bl7wghfMdDWeUrod04i4PTOXdivfU7c3SZIkSao7w48kSZKkgWD4kSRJkjQQDD/TUJ+rpSRJkrQ7qNP19ru7fo6l4acPDvYmSZKkqZo7dy4PP/ywAWgnyEwefvhh5s6dO6XlHOpakiRJ2gUWLVrEmjVrWLdu3UxX5Slh7ty5LFq0aErLGH4kSZKkXWDWrFkcdthhM12NgWa3N0mSJEkDwfAjSZIkaSAYfqbBa9UkSZKk+jD89CHC8d4kSZKkujH8SJIkSRoIhh9JkiRJA8HwI0mSJGkgGH6mxREPJEmSpLow/PTB4Q4kSZKk+jH8SJIkSRoIhh9JkiRJA8HwI0mSJGkgGH4kSZIkDQTDzzSkg71JkiRJtWH46UM43JskSZJUO4YfSZIkSQPB8CNJkiRpIBh+JEmSJA0Ew48kSZKkgWD4mQYHe5MkSZLqw/DTh8Dh3iRJkqS6MfxIkiRJGgiGH0mSJEkDwfAjSZIkaSAYfiRJkiQNBMPPNKTDvUmSJEm1YfjpQzjYmyRJklQ7hh9JkiRJA8HwI0mSJGkgGH4kSZIkDQTDjyRJkqSBYPiZhnS4N0mSJKk2DD99cLA3SZIkqX4MP5IkSZIGguFHkiRJ0kDoKfxExMkRsTIiVkXEhV3mR0RcUs6/MyKOqcxbHRE/jIg7ImJ5Zfp+EXFTRPykfN535+ySJEmSJG1r0vATEU3gU8ApwBHAmRFxREexU4DF5eNc4NKO+Sdm5pLMXFqZdiFwc2YuBm4u30uSJEnSk6KXlp9jgVWZeW9mDgPLgNM6ypwGfCELtwLzI2LhJOs9DbiyfH0l8Ibeq717cKw3SZIkqT56CT8HAfdV3q8pp/VaJoGvRcTtEXFupczTM3MtQPl8YLeNR8S5EbE8IpavW7euh+ruAg73JkmSJNVOL+Gn21f9zkaPHZU5PjOPoegad35EvHIK9SMzL8/MpZm5dMGCBVNZVJIkSZLG9RJ+1gAHV94vAu7vtUxmtp8fBK6l6EYH8EC7a1z5/OBUKy9JkiRJveol/NwGLI6IwyJiNnAGcF1HmeuAs8pR344D1mfm2oiYFxF7A0TEPOBXgbsqy5xdvj4b+Idp7oskSZIkbdfQZAUyczQiLgBuBJrAFZm5IiLOK+dfBtwAnAqsAjYC7ygXfzpwbUS0t3V1Zn61nPdx4JqIeBfwM+D0nbZXu0g64oEkSZJUG5OGH4DMvIEi4FSnXVZ5ncD5XZa7FzhqO+t8GHj1VCq7uwhHPJAkSZJqp6ebnEqSJElS3Rl+JEmSJA0Ew08f9lr3fa6e9X8zd/1/zHRVJEmSJPXI8NOHoS2/4GXNH9EceXymqyJJkiSpR4YfSZIkSQPB8NOHcLA3SZIkqXYMP5IkSZIGguFHkiRJ0kAw/ExLznQFJEmSJPXI8NMXL/qRJEmS6sbwMx02/EiSJEm1YfiRJEmSNBAMP5IkSZIGguFnWuz3JkmSJNWF4acf3uVUkiRJqh3DjyRJkqSBYPiZBju9SZIkSfVh+OlDeJ8fSZIkqXYMP5IkSZIGguFnOtKOb5IkSVJdGH764WhvkiRJUu0YfiRJkiQNBMOPJEmSpIFg+JEkSZI0EAw/kiRJkgaC4Wc6HO1NkiRJqg3DTz8c7E2SJEmqHcPPNCS2/EiSJEl1Yfjpgw0/kiRJUv0YfiRJkiQNBMOPJEmSpIFg+JEkSZI0EAw/ffGqH0mSJKluDD/T4WBvkiRJUm0Yfvphw48kSZJUO4YfSZIkSQPB8DMt9nuTJEmS6sLw0xf7vUmSJEl1Y/iRJEmSNBAMP9NgpzdJkiSpPgw/fbHbmyRJklQ3hh9JkiRJA8HwMx1pxzdJkiSpLnoKPxFxckSsjIhVEXFhl/kREZeU8++MiGM65jcj4vsRcX1l2kcj4ucRcUf5OHX6u7OLhN3eJEmSpLoZmqxARDSBTwGvAdYAt0XEdZn5o0qxU4DF5eOlwKXlc9v7gLuBfTpW/xeZeXH/1ZckSZKk3vTS8nMssCoz783MYWAZcFpHmdOAL2ThVmB+RCwEiIhFwGuBz+7Eeu8m7PYmSZIk1UUv4ecg4L7K+zXltF7LfBL4INDqsu4Lym5yV0TEvj3VeDdgpzdJkiSpfnoJP92+63c2eXQtExGvAx7MzNu7zL8UeDawBFgLfKLrxiPOjYjlEbF83bp1PVRXkiRJkrbVS/hZAxxceb8IuL/HMscDr4+I1RTd5V4VEX8DkJkPZOZYZraAz1B0r9tGZl6emUszc+mCBQt6qO4u5GhvkiRJUm30En5uAxZHxGERMRs4A7iuo8x1wFnlqG/HAeszc21mXpSZizLz0HK5b2Tm2wDa1wSV3gjcNd2d2WUc7U2SJEmqnUlHe8vM0Yi4ALgRaAJXZOaKiDivnH8ZcANwKrAK2Ai8o4dt/1lELKHoQrcaeE8/OyBJkiRJvZg0/ABk5g0UAac67bLK6wTOn2QdtwC3VN6/fQr13C3Z6U2SJEmqj55ucipJkiRJdWf4kSRJkjQQDD/TYsc3SZIkqS4MP31xtDdJkiSpbgw/02HDjyRJklQbhp8+eJsfSZIkqX4MP5IkSZIGguFHkiRJ0kAw/ExDeNGPJEmSVBuGn7540Y8kSZJUN4afabDdR5IkSaoPw48kSZKkgWD4kSRJkjQQDD/TkXZ8kyRJkurC8NMP73IqSZIk1Y7hR5IkSdJAMPxMg53eJEmSpPow/PTBTm+SJElS/Rh+JEmSJA0Ew880hKO9SZIkSbVh+OmHo71JkiRJtWP4kSRJkjQQDD/TYKc3SZIkqT4MP30Ix3uTJEmSasfwI0mSJGkgGH6mw9HeJEmSpNow/PQh7fYmSZIk1Y7hR5IkSdJAMPxMg53eJEmSpPow/PTBe5xKkiRJ9WP4kSRJkjQQDD/TEHZ8kyRJkmrD8CNJkiRpIBh+JEmSJA0Ew880eI9TSZIkqT4MP5IkSZIGguFHkiRJ0kAw/EyL/d4kSZKkujD89MO7nEqSJEm1Y/iZBtt9JEmSpPow/PTBhh9JkiSpfgw/kiRJkgaC4Wcawo5vkiRJUm0YfvqQ2O9NkiRJqpuewk9EnBwRKyNiVURc2GV+RMQl5fw7I+KYjvnNiPh+RFxfmbZfRNwUET8pn/ed/u5IkiRJUneThp+IaAKfAk4BjgDOjIgjOoqdAiwuH+cCl3bMfx9wd8e0C4GbM3MxcHP5vlbSXm+SJElSbfTS8nMssCoz783MYWAZcFpHmdOAL2ThVmB+RCwEiIhFwGuBz3ZZ5sry9ZXAG/rbhV0v7PYmSZIk1U4v4ecg4L7K+zXltF7LfBL4INDqWObpmbkWoHw+sLcqS5IkSdLU9RJ+ujVzdHb46lomIl4HPJiZt0+5Zu0VR5wbEcsjYvm6dev6Xc2Tw35vkiRJUm30En7WAAdX3i8C7u+xzPHA6yNiNUV3uVdFxN+UZR6odI1bCDzYbeOZeXlmLs3MpQsWLOihuruC3d4kSZKkuukl/NwGLI6IwyJiNnAGcF1HmeuAs8pR344D1mfm2sy8KDMXZeah5XLfyMy3VZY5u3x9NvAP090ZSZIkSdqeockKZOZoRFwA3Ag0gSsyc0VEnFfOvwy4ATgVWAVsBN7Rw7Y/DlwTEe8Cfgac3t8uzCS7vUmSJEl1MWn4AcjMGygCTnXaZZXXCZw/yTpuAW6pvH8YeHXvVd19hL3eJEmSpNrp6SankiRJklR3hp9pCLu9SZIkSbVh+OmL/d4kSZKkujH8SJIkSRoIhp9p8B6nkiRJUn0YfvphrzdJkiSpdgw/kiRJkgaC4UeSJEnSQDD89MO7nEqSJEm1Y/iRJEmSNBAMP9PgYG+SJElSfRh++mCnN0mSJKl+DD+SJEmSBoLhZxrCjm+SJElSbRh++mLHN0mSJKluDD/TkDb8SJIkSbVh+OmDt/mRJEmS6sfwI0mSJGkgGH6mxX5vkiRJUl0YfvpivzdJkiSpbgw/kiRJkgaC4Wda7PYmSZIk1YXhR5IkSdJAMPxIkiRJGgiGn+nwLqeSJElSbRh++uFdTiVJkqTaMfxIkiRJGgiGn2mw05skSZJUH4afPtjpTZIkSaofw48kSZKkgWD4mQ5He5MkSZJqw/DTD0d7kyRJkmrH8CNJkiRpIBh+JEmSJA0Ew09f7PYmSZIk1Y3hR5IkSdJAMPxIkiRJGgiGn77Y7U2SJEmqG8OPJEmSpIFg+JmG9CankiRJUm0YfvphrzdJkiSpdgw/kiRJkgaC4WcaAru9SZIkSXVh+OlH2O9NkiRJqpuewk9EnBwRKyNiVURc2GV+RMQl5fw7I+KYcvrciPhuRPwgIlZExB9WlvloRPw8Iu4oH6fuvN2SJEmSpK0NTVYgIprAp4DXAGuA2yLiusz8UaXYKcDi8vFS4NLyeQvwqsx8PCJmAf8SEV/JzFvL5f4iMy/eebuza7TbfRzsTZIkSaqPXlp+jgVWZea9mTkMLANO6yhzGvCFLNwKzI+IheX7x8sys8pH7SPDePip/65IkiRJA6OX8HMQcF/l/ZpyWk9lIqIZEXcADwI3ZeZ3KuUuKLvJXRER+3bbeEScGxHLI2L5unXreqjuk2/8ih+zjyRJklQbvYSfblf3d37t326ZzBzLzCXAIuDYiPilcv6lwLOBJcBa4BPdNp6Zl2fm0sxcumDBgh6quws0it01+0iSJEn10Uv4WQMcXHm/CLh/qmUy81HgFuDk8v0DZTBqAZ+h6F5XC4HhR5IkSaqbXsLPbcDiiDgsImYDZwDXdZS5DjirHPXtOGB9Zq6NiAURMR8gIvYATgLuKd8vrCz/RuCu6e3KrjPR7c34I0mSJNXFpKO9ZeZoRFwA3Ag0gSsyc0VEnFfOvwy4ATgVWAVsBN5RLr4QuLIcMa4BXJOZ15fz/iwillA0oKwG3rOzdurJ1r7Nj9FHkiRJqo9Jww9AZt5AEXCq0y6rvE7g/C7L3QkcvZ11vn1KNd2NRJl+0pYfSZIkqTZ6usmptsPwI0mSJNWG4acP4y0/M1wPSZIkSb0z/PQhuo7sLUmSJGl3ZvjpgwMeSJIkSfVj+OnDePgx/UiSJEm1YfiZDtOPJEmSVBuGnz5MdHsz/EiSJEl1Yfjpw/iAB2YfSZIkqTYMP31wqGtJkiSpfgw/fWgPdG34kSRJkurD8NMP048kSZJUO4afPtjtTZIkSaofw08f2g0/ZGsmqyFJkiRpCgw/fRhv+bHpR5IkSaoNw08fJrq9mX4kSZKkujD8SJIkSRoIhp8+hPc4lSRJkmrH8NOHBqYfSZIkqW4MP/0om35ajnggSZIk1Ybhpw8Rk5eRJEmStHsx/PRh4j4/tvxIkiRJdWH4mQajjyRJklQfhp8+tFt+DD+SJElSfRh++hDjY10bfyRJkqS6MPz0odEowo/ZR5IkSaoPw08fouz4ZvaRJEmS6sPwMx02/UiSJEm1YfiZBqOPJEmSVB+GH0mSJEkDwfAzDWnbjyRJklQbhp9+jA91PbPVkCRJktQ7w880tAw/kiRJUm0YfqbF9CNJkiTVheFHkiRJ0kAw/EyD7T6SJElSfRh+piNbM10DSZIkST0y/PSlGO0tbfqRJEmSasPwMw2GH0mSJKk+DD/TYPaRJEmS6sPwI0mSJGkgGH4kSZIkDQTDzzSko71JkiRJtWH46UfETNdAkiRJ0hT1FH4i4uSIWBkRqyLiwi7zIyIuKeffGRHHlNPnRsR3I+IHEbEiIv6wssx+EXFTRPykfN535+3WruFob5IkSVJ9TBp+IqIJfAo4BTgCODMijugodgqwuHycC1xaTt8CvCozjwKWACdHxHHlvAuBmzNzMXBz+b5WDD+SJElSffTS8nMssCoz783MYWAZcFpHmdOAL2ThVmB+RCws3z9elplVPrKyzJXl6yuBN0xjP2aE2UeSJEmqj17Cz0HAfZX3a8ppPZWJiGZE3AE8CNyUmd8pyzw9M9cClM8HTrn2M874I0mSJNVFL+Gn29X9nd/6t1smM8cycwmwCDg2In5pKhWMiHMjYnlELF+3bt1UFn0StXfX8CNJkiTVRS/hZw1wcOX9IuD+qZbJzEeBW4CTy0kPRMRCgPL5wW4bz8zLM3NpZi5dsGBBD9XddbzmR5IkSaqPXsLPbcDiiDgsImYDZwDXdZS5DjirHPXtOGB9Zq6NiAURMR8gIvYATgLuqSxzdvn6bOAfprcrM8DwI0mSJNXG0GQFMnM0Ii4AbgSawBWZuSIizivnXwbcAJwKrAI2Au8oF18IXFmOGNcArsnM68t5HweuiYh3AT8DTt95u7VreItTSZIkqT4mDT8AmXkDRcCpTrus8jqB87ssdydw9HbW+TDw6qlUVpIkSZL61dNNTrUdXvQjSZIk1Ybhpx9RjPaWXvQjSZIk1YbhZzrMPpIkSVJtGH6mwewjSZIk1YfhR5IkSdJAMPxMQ8umH0mSJKk2DD/TYvqRJEmS6sLw048oD1t6m1NJkiSpLgw//SiHug5bfiRJkqTaMPz0o2z5CVt+JEmSpNow/PTDbm+SJElS7Rh++lJ0eyPt9iZJkiTVheGnH+2WH2z5kSRJkurC8NOP8Wt+bPmRJEmS6sLw0492+HG0N0mSJKk2DD/9cMADSZIkqXYMP/0Yv8+P4UeSJEmqC8NPP8Zbfuz2JkmSJNWF4acf7ZYfu71JkiRJtWH46cf4UNe2/EiSJEl1Yfjpx/hQ17b8SJIkSXVh+OlLe8ADW34kSZKkujD89MMBDyRJkqTaMfz0Y/wmp3Z7kyRJkurC8NMPb3IqSZIk1Y7hpx/jQ13b7U2SJEmqC8NPP+z2JkmSJNWO4acf3udHkiRJqh3DTz/s9iZJkiTVjuGnTy0adnuTJEmSasTw06cEwtHeJEmSpNow/PQpaXjJjyRJklQjhp8+tQi7vUmSJEk1YvjpU0YDDD+SJElSbRh++pSEo71JkiRJNWL46VMRfmz5kSRJkurC8NOnJEhHPJAkSZJqw/DTp4wG2PIjSZIk1Ybhp09e8yNJkiTVi+GnT7b8SJIkSfVi+Omb9/mRJEmS6sTw06ckwG5vkiRJUm0YfvpktzdJkiSpXgw/fUoahENdS5IkSbXRU/iJiJMjYmVErIqIC7vMj4i4pJx/Z0QcU04/OCK+GRF3R8SKiHhfZZmPRsTPI+KO8nHqztutJ19G2PIjSZIk1cjQZAUiogl8CngNsAa4LSKuy8wfVYqdAiwuHy8FLi2fR4HfzszvRcTewO0RcVNl2b/IzIt33u7sSkEYfiRJkqTa6KXl51hgVWbem5nDwDLgtI4ypwFfyMKtwPyIWJiZazPzewCZuQG4GzhoJ9Z/xmQ0wG5vkiRJUm30En4OAu6rvF/DtgFm0jIRcShwNPCdyuQLym5yV0TEvr1WevdgtzdJkiSpTnoJP9FlWmeTxw7LRMRewJeA92fmY+XkS4FnA0uAtcAnum484tyIWB4Ry9etW9dDdXeNDAc8kCRJkuqkl/CzBji48n4RcH+vZSJiFkXwuSoz/75dIDMfyMyxzGwBn6HoXreNzLw8M5dm5tIFCxb0UN1dI2l4zY8kSZJUI72En9uAxRFxWETMBs4Arusocx1wVjnq23HA+sxcGxEBfA64OzP/vLpARCysvH0jcFffezETAlt+JEmSpBqZdLS3zByNiAuAG4EmcEVmroiI88r5lwE3AKcCq4CNwDvKxY8H3g78MCLuKKd9KDNvAP4sIpZQdI9bDbxnJ+3TLtKANPxIkiRJdTFp+AEow8oNHdMuq7xO4Pwuy/0L3a8HIjPfPqWa7maKa37s9iZJkiTVRU83OVUX0SBs+ZEkSZJqw/DTtyBokQYgSZIkqRYMP33KCIL0sh9JkiSpJgw//Srv8zNm+pEkSZJqwfDTp4wGDZKxluFHkiRJqgPDT9+K8NOy5UeSJEmqBcNPvyJo0LLlR5IkSaoJw0+/orh9kdlHkiRJqgfDT7+iQYMWLdOPJEmSVAuGn361Bzzwmh9JkiSpFgw/fWvQiLTlR5IkSaoJw0+/ypuc2vIjSZIk1YPhp1/lTU5t+JEkSZLqwfDTr4jiPj+mH0mSJKkWDD/9igZN7/MjSZIk1Ybhp0/ZGCpucuo1P5IkSVItGH76FU2GGLPbmyRJklQThp9+NYaKbm+2/EiSJEm1YPjpUzaaNGnRas10TSRJkiT1wvDTr2jSZIyWLT+SJElSLRh++hSNIYYYY2TMph9JkiSpDgw/fYrmEI1IRsZs+ZEkSZLqwPDTp2g0bfmRJEmSamRopitQV43mEMEYw6OGH0mSJKkODD99iuYsGrQYtuVHkiRJqgXDT58azWKoa7u9SZIkSfXgNT99ajRn0bTbmyRJklQbhp8+NZpDtvxIkiRJNWL46VOzDD+2/EiSJEn1YPjpU2NoiFkxxrD3+ZEkSZJqwfDTp2ZzFgDDI6MzXBNJkiRJvTD89Kk5VAyUNzY6MsM1kSRJktQLw0+fGs0i/IyOGH4kSZKkOjD89KtRtvyMGX4kSZKkOjD89KtRXPMzOjI8wxWRJEmS1AvDT7+G5hTPo5tnth6SJEmSemL46dfQXAByxPAjSZIk1YHhp1+zivAzZviRJEmSasHw06+y5Wd0y6YZrogkSZKkXhh++lVe8zM2vHGGKyJJkiSpF4affpUtP2PDdnuTJEmS6sDw06+y5ccBDyRJkqR6MPz0a2gPANKhriVJkqRaMPz0q32fH1t+JEmSpFroKfxExMkRsTIiVkXEhV3mR0RcUs6/MyKOKacfHBHfjIi7I2JFRLyvssx+EXFTRPykfN535+3WLlBe88PoZjJzZusiSZIkaVKThp+IaAKfAk4BjgDOjIgjOoqdAiwuH+cCl5bTR4HfzswXAMcB51eWvRC4OTMXAzeX7+ujDD+zGWHj8NgMV0aSJEnSZHpp+TkWWJWZ92bmMLAMOK2jzGnAF7JwKzA/IhZm5trM/B5AZm4A7gYOqixzZfn6SuAN09uVXay8yekchlm/aWSGKyNJkiRpMr2En4OA+yrv1zARYHouExGHAkcD3yknPT0z1wKUzwd223hEnBsRyyNi+bp163qo7i5StvzsGVt45InhGa6MJEmSpMn0En6iy7TOi1x2WCYi9gK+BLw/Mx/rvXqQmZdn5tLMXLpgwYKpLPrkajQZnb0P83mcX2wchuEn4O7r4e/eBV+5EB65d6ZrKEmSJKliqIcya4CDK+8XAff3WiYiZlEEn6sy8+8rZR5od42LiIXAg1Ot/Exr7bEf+256nCd+8V/wtyfB6GZoDAEBd1wN534T9n/2TFdTVZnlowWUz+OPjvcwyfzsmL69+e0Hk8zvWA8JrTFojRTvx0aL17P2AAJaoxCN4tGcVZYdLco2msX75qyJ/aay79EoWy9z62NTvJjkPRABwxsntl+dXtV+nzlRt3ZdGkPFtKJgx3uK9Taa2x7XiGLe+P6Olcs3d/y5bz2hUpeO41P9XNr711mHWcVQ97TGiu23j0H7fWus/F1QOeaZRd2bsyfKkNCcU74fhVarGEkyx4rXrVFoDhUfQWuk/JxbMDZcfH6tkfJznl1MI4vXrdGyLq3y/UhZH4pyjVnlOdVez+jEMW+NlPtTnmPt5dvbaY1OfK5jo5XPqDzf2tO22lZZl8asibpkFvPb5277nGgvQ05sf3TLtvOzVay3vc4ot9kaKY7p2HD5+QWMjRTHdWykWE80i9fNdt2yqPPYyMT+tMaKYz82Wvl8q+uO8hiV01ojE+upfibtZceGK3Uoj3W2ymNWLVfWdXTL1uf6eLlmsQ9jozA0e2I/WqNb70fnz+V4ubGObc2G0cr+tOs0uqX8nMrfhY1mMa19/rZ/Lqr7Vf091JxVTpvdcWwqn2n788lWsa3ObUZj63NkfJ/an+HwxOfVuZ/Vc7NV1qPrMRje+mdkvP6zK/Pa62pVzqX2vLHKz8PwxLkQZfnqObPVuqrHrvJz0v6/5OrnWv1dss0xqXxujWbxWbbXH2x9/owOdxzDjnOLKNY3fu5Xjlv7mI8fmy0T68r27/P2vm6p/D6prL99HKrrqh7LsZGJn+nqsRlf12jlc2yfV+W5U/1cGu2fh8rPYftzaZ9f1X1r/xx1nqNbnRNjE59H+9ze6ue9rHP1Z39ozta/W8fr0f5MmTg3W6Pl8W//XhgqPq/q773xvxWVbbTPjfFj2fH7e2h2+TssJn5m2vUaG5n4O9L+Wzc2MlG/9jnWPj7tvxdjIxPra5XHvTVWTP+1j8GL/hu7u17Cz23A4og4DPg5cAbw3zvKXAdcEBHLgJcC68tQE8DngLsz88+7LHM28PHy+R/6342ZEXvuz76PbGDvlVcXwedVH4bj/xes/xlcfgL87dvg1/8SDj52pqu687XGYOMj8MS6yuMh2PjQxOtNj8LwhuIHNmKa4SEnmd9juNim0VKqufYfy/E/nOUXu2oYaP8Bh63/aDaGii8q7TAxHp7KstUvvONfPmZN/IEdX1eTibA0ayJEtL+UjP+hH534AhHNiS9Y7bDUak0EjkZj6y88MBGgqtusfsGJ5kSd23+QofLlYfbEfrbXM/4fBNV1D229v9X/aGh/WWqVQXx83bMmfkdttWz5ebSPdfsLTPuL7Hj9y+NQ/YLSDgFQfgmZs2255uzi709z9kSQGP8Mhia+IFeDY/sLePX4ZnvgnvY62nVqTNSjWQal5tDEMWnMKn7vV8+r9hfb6j4XB7k8ho9OfD7t4NDev5FNlQBUno/DT2wdmNpBoDm7uN1EY2giOLSD23j9hyaOWzvoVT/TWXtUvgSWXxZjj/L13sU+zd5z4nOcPa8oP2vPiS+D7W3P2afc3722PRbN+WW9Kud/9bxslx/fj9kTx6795bT9N6wdMBqV/Wifw9Uv7ePnT+XnZDz4ZSUst382cuvPo/0FfGj21gFzPAiMbb3tdvBu/5yN/wfB6ET4Gl9Xbn0Oj/8sVsLw+LmTE/sxvq7NHedVdV3lsWn/fDVmTfyMVH/3tUYqvwdmb70f7d8h7c+sHeQ661UNpENzi8DZqq5j9sT3l/Fzs/y9F83i56t9XFrlOV8NLu3vNV1/V1Z+F0aj+L05/h82UQlcXX6nD82uHLPyPwugWL59XmZZl7Gyfo1ZlXO4/R9W5foas4rp859FHUwafjJzNCIuAG4EmsAVmbkiIs4r518G3ACcCqwCNgLvKBc/Hng78MOIuKOc9qHMvIEi9FwTEe8CfgacvtP2ahcZmn8Qh9//b8z/6TJ4zmvglb9bzNjvcHjzFXDtufC518BzToJXfwQWvmhmKzyZVgs2PgybH4XHH4BfrC4CzIa18OjP4NGfwpbHi/kbH6FrkIgG7HkAzDsA9tgX9npG8UunPW/8EVu/n3R+dEzf3vz2vB3N71Km6/zK6x3Oby/fWYftrZsuy3Zbd7ndxlD5RXLWxC+a9i/7drBrf9EY/0IzNvGHCDr2ofzjNf4/au3Wmuh4321aMB4qZ8+b+KUOE+dD5/u29hfK8f+pHGP8C3q7lat6PrRbPzqPdXufx/e3OVGnquof8uq+VM/V8eNSea5ur9160v5frvYyI5vKz6Yx8TnARH3af3TH11n5otn+X+GtWkeGJlqN2y3I7f0b3VIJEh1fzNuhov0Hu/15NCr/I9v+/Fqtrad3ttJJkjQAok73qFm6dGkuX758pqsx4Zt/Av/88eL126+FZ79q6/lbHofbPgP/+pew6RdwwHPh2a+GxSfBIS8fHzHuSZNZfJHa+DBsfqxokRl+HDb8V/Fov1//c3hsDTy2tvhi1mlobpHm5z8L5uwNe+wH8xYUAWfeAeXrBUXo2WPfiS9YkiRJ0i4WEbdn5tKu8ww/0/Bfd8Flx/MA+3LgH9xLbO9L/6ZfFNcArboZfvqvRSCZtSccfiK84NeLFqH5h8CcvSbf5sgmeOz+ohXmiYdhw/3F+jc+ApsegY2/KJ8fLh7VayiqogFz5xdh5mmLYJ9nwj4HFc9znwZ7HQj7HlqUmTvfQCNJkqRa2FH46eWaH23PM36Jm196Bb/9zyN8+ZFNHHrAvO7l9tgXfvn84jGyCVb/C/z4Rrjnn2DlP02U23P/onVl74VFuZFNRcvM2HARmDathy3rt11/Y6hojdlzv+J5v8PhoBcX65u9VzF97tOK1pk5e8Pez4B5BxZ9OyVJkqQB4bffaXr6i07i0X/+F3748/XbDz9Vs/aAxa8pHqf8KaxbCQ/+qLympnz84qfFBZaz9oA9n1VcRDZrzyK47HUg7LMI9lpQttQcVEy3/74kSZK0Q4afaXru0/dmdrPBD+57lF8/6plTW7jRhKcfUTwkSZIkPam8kGOaZg81OP45+/PlO+5n88jY5AtIkiRJmhGGn53gPb/ybB56fAtX/tvqma6KJEmSpO0w/OwExx2+Py979v5ccvNP+O5/PjLT1ZEkSZLUheFnJ/nz/7aEA/aewxmX/ztv+NS/8p17H57pKkmSJEmqMPzsJM942lyu/82X89aXPIs77nuUt15+K6f85be55rb7+K/1m2e6epIkSdLA8yanT4If3Pcob7703wAYbRXH95cP359TX7SQXz58P55z4N4zWT1JkiTpKWtHNzk1/DyJtoyOcdfP1/PNe9bxDz/4Ofc9sgmAxQfuxRHP3IfFB+7FwqftwSH778mz9tuTBXvPIbxfjyRJktQ3w89uIDP53s9+wd/c+jPWbxrhnrWPcX9Hd7i5sxo8c/4e7D9vNvvNm81+8+ZwwF7F6z1mNYmARfvuybw5Q+w/bzZ7zm4yb84Qc4YahiZJkiSJHYcfb3K6i0QELz5kP158yH7j0zYNj7F2/SZ+9shG7ntkIz99eCNr12/m4Se2cO+6J1i++hf8YuMwrUnyabMRRRCaPcSec8rn2U32mjPEnnOGmDe7yZ6zh5g3Z+vnOUMNZg81mDPUYM5Qs/K6mD7UbDCrGcxuTrye1WjQaBi0JEmSVD+Gnxm0x+wmhy/Yi8MX7LXdMmOtZP2mER7bNMKDG7bwwGObaWUyPNpi4/AYTwyPsnHLGI9vGWXj8ChPDI+xcUvx/MCGzWx8aKLME8OjkwapXjQbwVCjHYqCWc1G+QgiYnx+sxEMNYsxNZoBc4aaNBrQbDSY1SiWa1SG3GhElA9olOtoRNBoFNOGGg0alRau9suhRrHdRrBV+eq62q+DGF8uxqcV+9RoxPj8dtnyH40opke0XxfLNsvXVUONoJU5Xtf2clCus12uGbQbXqNStyjXC5AU24+YqBftcu3pZbnMHH9frVJ1vdXtNTrqvVUdtjrGQUfR8W23X1c/j+hWvnLMo9v0ytSkOHZRXXlHmYn6brvebo2g43Nj6zLVhu/qco0u66tuv9s2Mrsf127lq/Wuvu+m+Oz8DwdJknYGw89urtmIsgvcbA49YN601pWZbBlt8cSWUZ7YMsaW0TG2jLbYMtpieLTFltExhkdbbB5tMTLaYrTVYngsGR1rMTLWYmQsy+cWo2PJcPk8MtZiuJyfmYy1ktHWxHMAo60WW0ZatEaTVo4x2moxMpqMVb59tlpJAq1MRseSVrmuVhbTRsZaxbd8xp/ILLaR5fKtzJ0S8KS6iK1z3TYBs3vZ7ZToWFc/6+hWn+2ua5sX3eePh8SuwXbHeg2Yk62tc7+2V2b7R7/zPyV2tJ7+wu7EfzLsoMykR6zXfZ38uHab2evnNcXVVpZvl+ntc5h0W72cv31sp5+PuL1PO/58p7rS/vevh1X0tK7qMZ7OMZ28Dj0uPEmx9n8wTnbVyPbq2nM9drCOybT/A7a3z2bHhXpZx1graTaCd778ME583oE91nLmGH4GSEQwd1aTubOa7L/9xqanhOwITpkwlkU4a2u1ynlQli3KJcVz+32xvomy7elF0Cq20/7lkRTvG1G0/rSXLeZtXb92MGzPyyymt8rndqvP+Dza9Su2TWVau3UgK3VmfLmJOrdbS4qAuPVv7mKfinVWl+12XeDEPnXsY24dTLfaSmXd2z8uRR1bnfvRpQJZWWabbXWt69b1amv/4d3q3NjhZ9eeVj2msdW0rbe/7XHeuj5dKt2eV1lf12Id+50dx3hH293+/B1WaJJ1bP+4TXV7kx3H6vrbn8OOtjF5mcnXwyTrmeyz3HZ93cptZ3rH8er8wpKVD6f9u2NH6263FG+7ne3/LG1blx2V2f7nNVkFk9zuF7Lq75zO6m/9e6j7Ona0/Dbr6T57qzI7KDGNZbe/th1dpz3V1Vb3s/NQVLe3owA43evGt/49v+N1TWdTndvp5/xqT08gW9DuGdJ9PeU2Ow9ul7+9261zD8dje3VsRDCarR62Mcn8Hg56UvRWaf/HdR0YfvSUFBEMNe0qJEmSpAne5FSSJEnSQDD8SJIkSRoIhh9JkiRJA8HwI0mSJGkgGH4kSZIkDQTDjyRJkqSBYPiRJEmSNBAMP5IkSZIGguFHkiRJ0kAw/EiSJEkaCIYfSZIkSQPB8CNJkiRpIBh+JEmSJA0Ew48kSZKkgWD4kSRJkjQQDD+SJEmSBoLhR5IkSdJAMPxIkiRJGgiRmTNdh55FxDrgpzNdj9IBwEMzXQnVkueO+uF5o3543qgfnjfqx+503hySmQu6zahV+NmdRMTyzFw60/VQ/XjuqB+eN+qH54364XmjftTlvLHbmyRJkqSBYPiRJEmSNBAMP/27fKYroNry3FE/PG/UD88b9cPzRv2oxXnjNT+SJEmSBoItP5IkSZIGguGnDxFxckSsjIhVEXHhTNdHMysiroiIByPirsq0/SLipoj4Sfm8b2XeReW5szIifq0y/cUR8cNy3iUREbt6X7TrRMTBEfHNiLg7IlZExPvK6Z472q6ImBsR342IH5TnzR+W0z1vtEMR0YyI70fE9eV7zxlNKiJWl5/5HRGxvJxW63PH8DNFEdEEPgWcAhwBnBkRR8xsrTTDPg+c3DHtQuDmzFwM3Fy+pzxXzgBeWC7z6fKcArgUOBdYXD4616mnllHgtzPzBcBxwPnl+eG5ox3ZArwqM48ClgAnR8RxeN5ocu8D7q6895xRr07MzCWVYaxrfe4YfqbuWGBVZt6bmcPAMuC0Ga6TZlBmfgt4pGPyacCV5esrgTdUpi/LzC2Z+Z/AKuDYiFgI7JOZ/57FhXhfqCyjp6DMXJuZ3ytfb6D4UnIQnjvagSw8Xr6dVT4SzxvtQEQsAl4LfLYy2XNG/ar1uWP4mbqDgPsq79eU06Sqp2fmWii+5AIHltO3d/4cVL7unK4BEBGHAkcD38FzR5Mouy/dATwI3JSZnjeazCeBDwKtyjTPGfUiga9FxO0RcW45rdbnztBMbbjGuvVRdMg89Wp754/n1YCKiL2ALwHvz8zHdtAN2nNHAGTmGLAkIuYD10bEL+2guOfNgIuI1wEPZubtEXFCL4t0meY5M7iOz8z7I+JA4KaIuGcHZWtx7tjyM3VrgIMr7xcB989QXbT7eqBs5qV8frCcvr3zZ035unO6nsIiYhZF8LkqM/++nOy5o55k5qPALRR95z1vtD3HA6+PiNUUXfVfFRF/g+eMepCZ95fPDwLXUlz+Uetzx/AzdbcBiyPisIiYTXFh13UzXCftfq4Dzi5fnw38Q2X6GRExJyIOo7jo77tls/GGiDiuHAHlrMoyegoqP+fPAXdn5p9XZnnuaLsiYkHZ4kNE7AGcBNyD5422IzMvysxFmXkoxXeWb2Tm2/Cc0SQiYl5E7N1+DfwqcBc1P3fs9jZFmTkaERcANwJN4IrMXDHD1dIMioj/A5wAHBARa4CPAB8HromIdwE/A04HyMwVEXEN8COK0b7OL7uwAPwGxchxewBfKR966joeeDvww/L6DYAP4bmjHVsIXFmOoNQArsnM6yPi3/G80dT4u0aTeTpF11ooMsPVmfnViLiNGp87UQy6IEmSJElPbXZ7kyRJkjQQDD+SJEmSBoLhR5IkSdJAMPxIkiRJGgiGH0mSJEkDwfAjSZIkaSAYfiRJkiQNBMOPJEmSpIHw/wNNuQvjrJivuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_mlp = MyMLP_v2(8, 1, learning_rate=0.01)\n",
    "my_mlp.add_hidden_layer(n_neurons=4, activation_function=ReLU())\n",
    "my_mlp.fit(X_train_scaled, y_train_scaled, valid_set=(X_val_scaled, y_val_scaled), epochs=5000, batch_size=32)\n",
    "\n",
    "\n",
    "y_train_pred = my_mlp.predict(X_train_scaled)\n",
    "y_test_pred = my_mlp.predict(X_test_scaled)\n",
    "y_val_pred = my_mlp.predict(X_val_scaled)\n",
    "\n",
    "mse_train = get_mse(y_train_scaled, y_train_pred)\n",
    "mse_test = get_mse(y_test_scaled, y_test_pred)\n",
    "mse_val = get_mse(y_val_scaled, y_val_pred)\n",
    "\n",
    "my_mlp.plot_learning_curve()\n",
    "\n",
    "print('\\n---- RESULTS ----')\n",
    "print('MSE Train:\\t', mse_train)\n",
    "print('MSE Test:\\t', mse_test)\n",
    "print('MSE Validation:\\t', mse_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Input Layer ----------\n",
      "N Neurons: 8\n",
      "Output Shape: (618, 9)\n",
      "Weights: (4, 9)\n",
      "Delta Shape: (618, 4)\n",
      "\n",
      "------- Hidden Layer 1 ---------\n",
      "N Neurons: 4\n",
      "Output Shape: (618, 5)\n",
      "Weights: (1, 5)\n",
      "Delta Shape: (618, 1)\n",
      "\n",
      "-------- Output Layer ----------\n",
      "N Neurons: 1\n",
      "Output Shape: (618, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\projects\\ufc\\machine-learning\\machine_learning\\supervised_learning\\programming_assignment_4\\programming_assignment_4.ipynb Cell 28'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/programming_assignment_4/programming_assignment_4.ipynb#ch0000028?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mOutput Shape:\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39mlayer_outputs[i]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/programming_assignment_4/programming_assignment_4.ipynb#ch0000028?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mlayers)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/programming_assignment_4/programming_assignment_4.ipynb#ch0000028?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mWeights:\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39;49mweights[i]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/programming_assignment_4/programming_assignment_4.ipynb#ch0000028?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDelta Shape:\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39mdeltas[i]\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = my_mlp\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    \n",
    "    if i == 0:\n",
    "        print(f'-------- Input Layer ----------')\n",
    "    elif i == len(model.layers)-1:\n",
    "        print(f'\\n-------- Output Layer ----------')\n",
    "    else:\n",
    "        print(f'\\n------- Hidden Layer {i} ---------')\n",
    "        \n",
    "\n",
    "\n",
    "    print('N Neurons:', model.layers[i])\n",
    "    print('Output Shape:', model.layer_outputs[i].shape)\n",
    "    \n",
    "    if i <= len(model.layers)-1:\n",
    "        print('Weights:', model.weights[i].shape)\n",
    "        print('Delta Shape:', model.deltas[i].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 907us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022614325788554903"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0), metrics=['mse'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=1, verbose=False)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# y_test_pred = y_scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "mse = get_mse(\n",
    "    y_test_scaled,\n",
    "    y_test_pred\n",
    ")\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23513d69c10>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35, 0.9 ],\n",
       "       [0.35, 0.9 ]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.layer_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00265449],\n",
       "        [0.00817165]]),\n",
       " array([[0.04068113]])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.35, 0.9 ]]), array([[0.755, 0.68 ]]), array([[0.6981492]])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.35, 0.9 ]]), array([[0.755, 0.68 ]]), array([[0.8385]])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.layer_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.35, 0.9 ]]), array([[0.6802672, 0.6637387]]), array([[0.69028349]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.35, 0.9 ]]), array([[0.755, 0.68 ]]), array([[0.80144499]])]"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.layer_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.35, 0.9 ]]), array([[0.6802672, 0.6637387]]), array([[0.69028349]])]"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01      ,  0.01      ],\n",
       "        [-1.30874051, -1.02080529],\n",
       "        [-0.73480594,  1.48559353]]),\n",
       " array([[ 0.        ],\n",
       "        [-0.96229814],\n",
       "        [-0.25849241]])]"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1]]), array([[-2.03354645,  0.47478824]]), array([[-0.12272916]])]"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.layer_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1]]), array([[0.        , 0.47478824]]), array([[-0.12272916]])]"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-4.0770929 ,  0.93957648]]), array([[-0.24287339]])]"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2, 2]]),\n",
       " array([[0.        , 0.        , 2.25006011]]),\n",
       " array([[1.72497389]])]"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.55005223],\n",
       "        [-0.55005223]]),\n",
       " array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.61882529]])]"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01      ,  0.01      ,  0.01      ],\n",
       "        [-1.02080529, -0.73480594,  1.48559353],\n",
       "        [-0.52143647, -1.36089508, -0.36556347]]),\n",
       " array([[ 0.01      ,  0.01      ],\n",
       "        [-1.25788996,  1.08418502],\n",
       "        [ 0.75540738,  0.68650945],\n",
       "        [ 0.60064027,  0.32373336]]),\n",
       " array([[ 0.        ],\n",
       "        [-1.01657088],\n",
       "        [-1.08121814]])]"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.initialize_weights()\n",
    "my_mlp.hidden_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2, 2]]),\n",
       " array([[0.        , 0.        , 2.25006011]]),\n",
       " array([[1.36147672, 0.73841953]]),\n",
       " array([[-2.18243018]])]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp.hidden_activation_values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "befc19283823365b4b77b90dae63e668f3a40f1a2491259fc4e466c5bacb6daf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
