{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2\n",
    "## Logistic Regression and Stochastic Methods\n",
    "\n",
    "Aluno: Francisco Edyvalberty Alenquer Cordeiro \\\n",
    "Matr√≠cula: 518659\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(y_real, y_pred):\n",
    "    return np.mean((y_real - y_pred) ** 2)\n",
    "\n",
    "def get_rmse(y_real, y_pred):\n",
    "    return np.sqrt(get_mse(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.mean = data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (scaled_data * self.std) + self.mean\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.maximum = data.max(axis=0)\n",
    "        self.minimum = data.min(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (self.maximum - self.minimum) * scaled_data + self.minimum\n",
    "        return original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data, train_size_perc, random_seed=264852):\n",
    "    N = data.shape[0]\n",
    "    train_size = int(train_size_perc * N)\n",
    "\n",
    "    indexes = np.arange(0, N, 1)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(indexes, train_size, replace=False)\n",
    "    test_idx = np.delete(indexes, train_idx)\n",
    "\n",
    "    train_data = data[train_idx]\n",
    "    test_data = data[test_idx]\n",
    "\n",
    "    X_train = train_data[:,:-1]\n",
    "    y_train = train_data[:,[-1]]\n",
    "\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,[-1]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.49765184, -0.56867644, -1.47949837, ..., -1.72684485,\n",
       "        -0.73743158,  0.256437  ],\n",
       "       [ 0.18395277, -1.22255334,  0.28189505, ..., -0.02826581,\n",
       "        -0.09974236,  0.44389088],\n",
       "       [ 1.86386334, -0.45207601,  1.78205271, ...,  1.51087983,\n",
       "        -0.33011176, -0.7327511 ],\n",
       "       ...,\n",
       "       [ 0.16418911,  1.07287467,  0.13220737, ..., -0.66201362,\n",
       "        -0.60889213, -0.62836716],\n",
       "       [-0.14920597, -0.09998845, -0.13312943, ...,  0.50062388,\n",
       "        -0.36850666, -0.38790155],\n",
       "       [ 0.72321818,  2.00110552,  0.69527912, ...,  0.4469684 ,\n",
       "        -1.11637256, -0.31466884]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(y, y_pred_proba):\n",
    "    cost_1 = y.T @ np.log(y_pred_proba)\n",
    "    cost_0 = (1-y).T @ np.log(1-y_pred_proba)\n",
    "    j = -(1/len(y)) * (cost_1 + cost_0)\n",
    "    return j.ravel()[0]\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    right_prediction = y == y_pred\n",
    "    accuracy = right_prediction.sum() / len(y)\n",
    "    return accuracy\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    right_prediction = y == y_pred\n",
    "    right_prediction = right_prediction[y == 1]\n",
    "    accuracy = right_prediction.sum() / y.sum()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyLogisticRegression():\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha, \n",
    "        n_iterations\n",
    "    ):        \n",
    "        self.alpha = alpha        \n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize(self, X, y, random_state=654812):\n",
    "        rnd_state = np.random.RandomState(random_state)\n",
    "        self.X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        self.y = y\n",
    "\n",
    "        self.w = rnd_state.uniform(\n",
    "            0, \n",
    "            1, \n",
    "            self.X.shape[1]\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, y, random_state=654812):\n",
    "        self.initialize(X, y, random_state)\n",
    "        self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        for i in range(self.n_iterations):\n",
    "            y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            e = (self.y - y_pred_proba) \n",
    "            self.w = self.w + ((1/len(self.y)) * self.alpha * (e.T @ self.X)).reshape(-1, 1)\n",
    "\n",
    "            # print(cross_entropy_loss(self.y, sigmoid(self.X @ self.w)))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        return predict_proba\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        predict_label = np.where(predict_proba>threshold, 1, 0)\n",
    "        return predict_label\n",
    "\n",
    "my_lr = MyLogisticRegression(0.1, 1000)\n",
    "my_lr.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.9736842105263158\n",
      "Recall: 1.0\n",
      "Log Loss: 0.08015880158280268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.97        45\n",
      "         1.0       0.96      1.00      0.98        69\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "my_y_pred = my_lr.predict(X_test_scaled)\n",
    "my_y_pred_proba = my_lr.predict_proba(X_test_scaled)\n",
    "print('Acuracy:', accuracy(y_test, my_y_pred))\n",
    "print('Recall:', recall(y_test, my_y_pred))\n",
    "print('Log Loss:', cross_entropy_loss(y_test, my_y_pred_proba))\n",
    "\n",
    "print(classification_report(y_test, my_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.,  1.,  0.,  1.,  2.,  1.,  2.,  2.,  5., 62.]),\n",
       " array([6.47383175e-11, 9.99996260e-02, 1.99999252e-01, 2.99998878e-01,\n",
       "        3.99998504e-01, 4.99998130e-01, 5.99997756e-01, 6.99997382e-01,\n",
       "        7.99997008e-01, 8.99996633e-01, 9.99996259e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(my_y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.9736842105263158\n",
      "Log Loss: 0.0685480140602806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.97        45\n",
      "         1.0       0.96      1.00      0.98        69\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edyalenquer\\.conda\\envs\\ml-project\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred = lr.predict(X_test_scaled)\n",
    "pred_proba = lr.predict_proba(X_test_scaled)\n",
    "\n",
    "print('Acuracy:', accuracy_score(y_test, pred))\n",
    "print('Log Loss:', log_loss(y_test, pred_proba))\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39.,  0.,  1.,  2.,  0.,  2.,  2.,  1.,  7., 60.]),\n",
       " array([1.82636744e-10, 9.99989581e-02, 1.99997916e-01, 2.99996874e-01,\n",
       "        3.99995832e-01, 4.99994790e-01, 5.99993748e-01, 6.99992706e-01,\n",
       "        7.99991664e-01, 8.99990622e-01, 9.99989580e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_proba[:, 1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d84fc3ab72c8387ddb373470e784917d8b759f8763a65d23fac12a2e8075760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
