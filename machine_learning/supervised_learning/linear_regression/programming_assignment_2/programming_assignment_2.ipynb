{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2\n",
    "## Logistic Regression and Stochastic Methods\n",
    "\n",
    "Aluno: Francisco Edyvalberty Alenquer Cordeiro \\\n",
    "Matr√≠cula: 518659\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(y_real, y_pred):\n",
    "    return np.mean((y_real - y_pred) ** 2)\n",
    "\n",
    "def get_rmse(y_real, y_pred):\n",
    "    return np.sqrt(get_mse(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.mean = data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (scaled_data * self.std) + self.mean\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.maximum = data.max(axis=0)\n",
    "        self.minimum = data.min(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data =  (data - self.minimum) / (self.maximum - self.minimum)\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (self.maximum - self.minimum) * scaled_data + self.minimum\n",
    "        return original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_cross_validation(data, n_folds=10, shuffle=False, random_state=12894):\n",
    "    indexes = np.arange(data.shape[0])\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(12894)\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "    slices = np.array_split(indexes, n_folds)\n",
    "    all_elements = np.hstack(slices)\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        train_idx = all_elements[~np.isin(all_elements, slices[i])]\n",
    "        test_idx = slices[i]\n",
    "\n",
    "        yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data, train_size_perc, random_seed=264852):\n",
    "    N = data.shape[0]\n",
    "    train_size = int(train_size_perc * N)\n",
    "\n",
    "    indexes = np.arange(0, N, 1)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(indexes, train_size, replace=False)\n",
    "    test_idx = np.delete(indexes, train_idx)\n",
    "\n",
    "    train_data = data[train_idx]\n",
    "    test_data = data[test_idx]\n",
    "\n",
    "    X_train = train_data[:,:-1]\n",
    "    y_train = train_data[:,[-1]]\n",
    "\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,[-1]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8, random_seed=12354)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(y, y_pred_proba):\n",
    "    cost_1 = y.T @ np.log(y_pred_proba)\n",
    "    cost_0 = (1-y).T @ np.log(1-y_pred_proba)\n",
    "    j = -(1/len(y)) * (cost_1 + cost_0)\n",
    "    return j.ravel()[0]\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    right_prediction = y_true == y_pred\n",
    "    accuracy = right_prediction.sum() / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    array = np.hstack([y_true.reshape(-1, 1), y_pred.reshape(-1, 1)])\n",
    "    array = array[array[:,0] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    recall = right_prediction.sum() / len(array)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    array = np.hstack([y_true.reshape(-1, 1), y_pred.reshape(-1, 1)])\n",
    "    array = array[array[:,1] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    precision = right_prediction.sum() / len(array)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_score = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "\n",
    "    f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha, \n",
    "        n_iterations\n",
    "    ):        \n",
    "        self.alpha = alpha        \n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize(self, X, y, random_state=654812):\n",
    "        rnd_state = np.random.RandomState(random_state)\n",
    "        self.X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        self.y = y\n",
    "\n",
    "        self.w = rnd_state.uniform(\n",
    "            0, \n",
    "            1, \n",
    "            self.X.shape[1]\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, y, random_state=654812):\n",
    "        self.initialize(X, y, random_state)\n",
    "        self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        self.loss_by_iteration = []\n",
    "        for i in range(self.n_iterations):\n",
    "            actual_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            e = (self.y - actual_y_pred_proba) \n",
    "            self.w = self.w + ((1/len(self.y)) * self.alpha * (e.T @ self.X)).reshape(-1, 1)\n",
    "\n",
    "            new_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            self.loss_by_iteration.append(cross_entropy_loss(self.y, new_y_pred_proba))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        return predict_proba\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        predict_label = np.where(predict_proba>threshold, 1, 0)\n",
    "        return predict_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9836 | Accuracy Std:   \t0.0019\n",
      "Recall Mean:     \t0.9928 | Recall Std:       \t0.0016\n",
      "Precision Mean:     \t0.9805 | Precision Std:   \t0.0021\n",
      "F1 Score Mean:     \t0.9866 | F1 Score Std:   \t0.0016\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9758 | Accuracy Std:   \t0.0270\n",
      "Recall Mean:     \t0.9926 | Recall Std:       \t0.0148\n",
      "Precision Mean:     \t0.9691 | Precision Std:   \t0.0388\n",
      "F1 Score Mean:     \t0.9802 | F1 Score Std:   \t0.0216\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9649\n",
      "Recall:     \t0.9877\n",
      "Precision:     \t0.9639\n",
      "F1 Score:     \t0.9756\n"
     ]
    }
   ],
   "source": [
    "train_metrics = {\n",
    "    'accuracy': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "valid_metrics = {\n",
    "    'accuracy': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "cv_splits = kfolds_cross_validation(\n",
    "    data=X_train,\n",
    "    n_folds=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for train_idx, val_idx in cv_splits:\n",
    "    # Spliting data\n",
    "    X_train_cv = X_train[train_idx, :]\n",
    "    y_train_cv = y_train[train_idx, :]\n",
    "    X_val_cv = X_train[val_idx, :]\n",
    "    y_val_cv = y_train[val_idx, :]\n",
    "\n",
    "    # Scaling X_train\n",
    "    X_scaler = StandardScaler()\n",
    "    X_train_cv_scaled = X_scaler.fit_transform(X_train_cv)\n",
    "\n",
    "    # Training Model\n",
    "    my_lr = MyLogisticRegression(0.1, 500)\n",
    "    my_lr.fit(X_train_cv_scaled, y_train_cv)\n",
    "\n",
    "    # Scaling X_val based on X_train\n",
    "    X_val_cv_scaled = X_scaler.transform(X_val_cv)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_cv_pred = my_lr.predict(X_train_cv_scaled)\n",
    "    y_val_cv_pred = my_lr.predict(X_val_cv_scaled)\n",
    "\n",
    "    # Storing metrics\n",
    "    train_metrics['accuracy'].append(accuracy(y_train_cv, y_train_cv_pred))\n",
    "    train_metrics['recall'].append(recall(y_train_cv, y_train_cv_pred))\n",
    "    train_metrics['precision'].append(precision(y_train_cv, y_train_cv_pred))\n",
    "    train_metrics['f1_score'].append(f1_score(y_train_cv, y_train_cv_pred))\n",
    "\n",
    "    valid_metrics['accuracy'].append(accuracy(y_val_cv, y_val_cv_pred))\n",
    "    valid_metrics['recall'].append(recall(y_val_cv, y_val_cv_pred))\n",
    "    valid_metrics['precision'].append(precision(y_val_cv, y_val_cv_pred))\n",
    "    valid_metrics['f1_score'].append(f1_score(y_val_cv, y_val_cv_pred))\n",
    "\n",
    "\n",
    "# Reporting results\n",
    "print('\\n--->\\tTraining Metrics')\n",
    "\n",
    "print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(np.mean(train_metrics['accuracy']), np.std(train_metrics['accuracy'])))\n",
    "print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(np.mean(train_metrics['recall']), np.std(train_metrics['recall'])))\n",
    "print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(np.mean(train_metrics['precision']), np.std(train_metrics['precision'])))\n",
    "print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(np.mean(train_metrics['f1_score']), np.std(train_metrics['f1_score'])))\n",
    "\n",
    "print('\\n--->\\tValidation Metrics')\n",
    "\n",
    "print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(np.mean(valid_metrics['accuracy']), np.std(valid_metrics['accuracy'])))\n",
    "print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(np.mean(valid_metrics['recall']), np.std(valid_metrics['recall'])))\n",
    "print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(np.mean(valid_metrics['precision']), np.std(valid_metrics['precision'])))\n",
    "print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(np.mean(valid_metrics['f1_score']), np.std(valid_metrics['f1_score'])))\n",
    "\n",
    "print('\\n--->\\tTest Metrics')\n",
    "\n",
    "# Scaling X_val based on X_train\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_test_pred = my_lr.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "print('Accuracy:     \\t{0:.4f}'.format(accuracy(y_test, y_test_pred)))\n",
    "print('Recall:     \\t{0:.4f}'.format(recall(y_test, y_test_pred)))\n",
    "print('Precision:     \\t{0:.4f}'.format(precision(y_test, y_test_pred)))\n",
    "print('F1 Score:     \\t{0:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 60.1578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edyalenquer\\.conda\\envs\\ml-project\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 114 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\projects\\ufc\\machine-learning\\machine_learning\\supervised_learning\\linear_regression\\programming_assignment_2\\programming_assignment_2.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000021?line=9'>10</a>\u001b[0m pred_proba \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict_proba(X_test_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000021?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAcuracy:\u001b[39m\u001b[39m'\u001b[39m, accuracy(y_test, pred))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000021?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRecall:\u001b[39m\u001b[39m'\u001b[39m, recall(y_test, pred))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000021?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLog Loss:\u001b[39m\u001b[39m'\u001b[39m, cross_entropy_loss(y_test, pred_proba[:, \u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000021?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, pred))\n",
      "\u001b[1;32mc:\\projects\\ufc\\machine-learning\\machine_learning\\supervised_learning\\linear_regression\\programming_assignment_2\\programming_assignment_2.ipynb Cell 15'\u001b[0m in \u001b[0;36mrecall\u001b[1;34m(y, y_pred)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000014?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall\u001b[39m(y, y_pred):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000014?line=15'>16</a>\u001b[0m     right_prediction \u001b[39m=\u001b[39m y \u001b[39m==\u001b[39m y_pred\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000014?line=16'>17</a>\u001b[0m     right_prediction \u001b[39m=\u001b[39m right_prediction[y \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000014?line=17'>18</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m right_prediction\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m y\u001b[39m.\u001b[39msum()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/projects/ufc/machine-learning/machine_learning/supervised_learning/linear_regression/programming_assignment_2/programming_assignment_2.ipynb#ch0000014?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 114 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred = lr.predict(X_test_scaled)\n",
    "pred_proba = lr.predict_proba(X_test_scaled)\n",
    "\n",
    "print('Acuracy:', accuracy(y_test, pred))\n",
    "print('Recall:', recall(y_test, pred))\n",
    "print('Log Loss:', cross_entropy_loss(y_test, pred_proba[:, 1]))\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39.,  0.,  1.,  2.,  0.,  2.,  2.,  1.,  7., 60.]),\n",
       " array([1.82636744e-10, 9.99989581e-02, 1.99997916e-01, 2.99996874e-01,\n",
       "        3.99995832e-01, 4.99994790e-01, 5.99993748e-01, 6.99992706e-01,\n",
       "        7.99991664e-01, 8.99990622e-01, 9.99989580e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_proba[:, 1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d84fc3ab72c8387ddb373470e784917d8b759f8763a65d23fac12a2e8075760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
