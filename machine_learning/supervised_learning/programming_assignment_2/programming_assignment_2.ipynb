{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2\n",
    "## Logistic Regression and Stochastic Methods\n",
    "\n",
    "Aluno: Francisco Edyvalberty Alenquer Cordeiro \\\n",
    "MatrÃ­cula: 518659\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "    right_prediction = y_true == y_pred\n",
    "    accuracy = right_prediction.sum() / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,0] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    recall = right_prediction.sum() / len(array)\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    array = np.hstack([y_true, y_pred])\n",
    "    array = array[array[:,1] == 1]\n",
    "    \n",
    "    right_prediction = array[:, 0] == array[:, 1]\n",
    "    precision = right_prediction.sum() / len(array)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.reshape(-1, 1)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    precision_score = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "\n",
    "    f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit_transform(self, data):      \n",
    "        self.mean = data.mean(axis=0)\n",
    "        self.std = data.std(axis=0)\n",
    "        self.fitted = True\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "\n",
    "        scaled_data = (data - self.mean) / self.std\n",
    "        return scaled_data\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Scaler not fitted!')\n",
    "        \n",
    "        original_data = (scaled_data * self.std) + self.mean\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_cross_validation(data, n_folds=10, shuffle=True, random_state=12894):\n",
    "    indexes = np.arange(data.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        np.random.shuffle(indexes)\n",
    "\n",
    "    slices = np.array_split(indexes, n_folds)\n",
    "    all_elements = np.hstack(slices)   \n",
    "    \n",
    "    splits = []\n",
    "    for i in range(n_folds):\n",
    "        train_idx = all_elements[~np.isin(all_elements, slices[i])]\n",
    "        test_idx = slices[i]\n",
    "\n",
    "        splits.append((train_idx, test_idx))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size_perc, random_seed=264852):\n",
    "    N = data.shape[0]\n",
    "    train_size = int(train_size_perc * N)\n",
    "\n",
    "    indexes = np.arange(0, N, 1)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    train_idx = np.random.choice(indexes, train_size, replace=False)\n",
    "    test_idx = np.delete(indexes, train_idx)\n",
    "\n",
    "    train_data = data[train_idx]\n",
    "    test_data = data[test_idx]\n",
    "\n",
    "    X_train = train_data[:,:-1]\n",
    "    y_train = train_data[:,[-1]]\n",
    "\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,[-1]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Cross Validation and Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cv_and_get_metrics(classifier, cv_splits, X_train, y_train, X_test, title='Classifier', scaler=None):\n",
    "\n",
    "    X_train = X_train.copy()\n",
    "    y_train = y_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    train_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    valid_metrics = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'precision': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        # Spliting data\n",
    "        X_train_cv = X_train[train_idx, :]\n",
    "        y_train_cv = y_train[train_idx, :]\n",
    "        X_val_cv = X_train[val_idx, :]\n",
    "        y_val_cv = y_train[val_idx, :]\n",
    "\n",
    "        # Scaling if have scaler argument\n",
    "        if scaler is not None:\n",
    "            X_train_cv = scaler.fit_transform(X_train_cv)\n",
    "            X_val_cv = scaler.transform(X_val_cv)\n",
    "\n",
    "        # Training Model\n",
    "        classifier.fit(X_train_cv, y_train_cv.ravel())\n",
    "\n",
    "        # Predictions\n",
    "        y_train_cv_pred = classifier.predict(X_train_cv)\n",
    "        y_val_cv_pred = classifier.predict(X_val_cv)\n",
    "\n",
    "        # Storing metrics\n",
    "        train_metrics['accuracy'].append(accuracy(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['recall'].append(recall(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['precision'].append(precision(y_train_cv, y_train_cv_pred))\n",
    "        train_metrics['f1_score'].append(f1_score(y_train_cv, y_train_cv_pred))\n",
    "\n",
    "        valid_metrics['accuracy'].append(accuracy(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['recall'].append(recall(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['precision'].append(precision(y_val_cv, y_val_cv_pred))\n",
    "        valid_metrics['f1_score'].append(f1_score(y_val_cv, y_val_cv_pred))\n",
    "\n",
    "\n",
    "    # Reporting results\n",
    "    print('#' + f'{title}'.center(60, '-') + '#')\n",
    "    print('\\n--->\\tTraining Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['accuracy']), \n",
    "        np.std(train_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['recall']), \n",
    "        np.std(train_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['precision']), \n",
    "        np.std(train_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(train_metrics['f1_score']), \n",
    "        np.std(train_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tValidation Metrics')\n",
    "\n",
    "    print('Accuracy Mean:     \\t{0:.4f} | Accuracy Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['accuracy']), \n",
    "        np.std(valid_metrics['accuracy']))\n",
    "    )\n",
    "    print('Recall Mean:     \\t{0:.4f} | Recall Std:       \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['recall']), \n",
    "        np.std(valid_metrics['recall']))\n",
    "    )\n",
    "    print('Precision Mean:     \\t{0:.4f} | Precision Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['precision']), \n",
    "        np.std(valid_metrics['precision']))\n",
    "    )\n",
    "    print('F1 Score Mean:     \\t{0:.4f} | F1 Score Std:   \\t{1:.4f}'.format(\n",
    "        np.mean(valid_metrics['f1_score']), \n",
    "        np.std(valid_metrics['f1_score']))\n",
    "    )\n",
    "\n",
    "    print('\\n--->\\tTest Metrics')\n",
    "\n",
    "    if scaler is not None:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "    print('Accuracy:     \\t{0:.4f}'.format(accuracy(y_test, y_test_pred)))\n",
    "    print('Recall:     \\t{0:.4f}'.format(recall(y_test, y_test_pred)))\n",
    "    print('Precision:     \\t{0:.4f}'.format(precision(y_test, y_test_pred)))\n",
    "    print('F1 Score:     \\t{0:.4f}'.format(f1_score(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8, random_seed=64825)\n",
    "\n",
    "cv_splits = kfolds_cross_validation(\n",
    "    data=X_train,\n",
    "    n_folds=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(y, y_pred_proba):\n",
    "    cost_1 = y.T @ np.log(y_pred_proba)\n",
    "    cost_0 = (1-y).T @ np.log(1-y_pred_proba)\n",
    "    j = -(1/len(y)) * (cost_1 + cost_0)\n",
    "    return j.ravel()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha, \n",
    "        n_iterations\n",
    "    ):        \n",
    "        self.alpha = alpha        \n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def initialize(self, X, y, random_state=654812):\n",
    "        rnd_state = np.random.RandomState(random_state)\n",
    "        self.X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        self.y = y\n",
    "\n",
    "        self.w = rnd_state.uniform(0, 1, self.X.shape[1]).reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, y, random_state=654812):\n",
    "        \n",
    "        if len(y.shape)==1:\n",
    "            y = y.reshape(-1, 1)\n",
    "            \n",
    "        self.initialize(X, y, random_state)\n",
    "        self.gradient_descent()\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        self.loss_by_iteration = []\n",
    "        for i in range(self.n_iterations):\n",
    "            actual_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            e = (self.y - actual_y_pred_proba) \n",
    "            \n",
    "            grad = ((1/len(self.y)) * self.alpha * (e.T @ self.X))\n",
    "            grad = grad.reshape(-1, 1)\n",
    "            self.w = self.w + grad \n",
    "            \n",
    "\n",
    "            new_y_pred_proba = sigmoid(self.X @ self.w)\n",
    "            self.loss_by_iteration.append(\n",
    "                cross_entropy_loss(self.y, new_y_pred_proba)\n",
    "            )\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        return predict_proba\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        X = np.hstack(\n",
    "            [np.ones((X.shape[0], 1)), X]\n",
    "        )\n",
    "        predict_proba = sigmoid(X @ self.w)\n",
    "        predict_label = np.where(predict_proba>threshold, 1, 0)\n",
    "        return predict_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------My Logistic Regression-------------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9858 | Accuracy Std:   \t0.0024\n",
      "Recall Mean:     \t0.9948 | Recall Std:       \t0.0031\n",
      "Precision Mean:     \t0.9822 | Precision Std:   \t0.0020\n",
      "F1 Score Mean:     \t0.9885 | F1 Score Std:   \t0.0020\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9649 | Accuracy Std:   \t0.0199\n",
      "Recall Mean:     \t0.9811 | Recall Std:       \t0.0267\n",
      "Precision Mean:     \t0.9606 | Precision Std:   \t0.0312\n",
      "F1 Score Mean:     \t0.9703 | F1 Score Std:   \t0.0199\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9912\n",
      "Recall:     \t0.9873\n",
      "Precision:     \t1.0000\n",
      "F1 Score:     \t0.9936\n"
     ]
    }
   ],
   "source": [
    "do_cv_and_get_metrics(\n",
    "    classifier=MyLogisticRegression(alpha=0.1, n_iterations=2000), \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    scaler=StandardScaler(),\n",
    "    title='My Logistic Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------Sklearn Logistic Regression-----------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9878 | Accuracy Std:   \t0.0019\n",
      "Recall Mean:     \t0.9980 | Recall Std:       \t0.0020\n",
      "Precision Mean:     \t0.9823 | Precision Std:   \t0.0020\n",
      "F1 Score Mean:     \t0.9901 | F1 Score Std:   \t0.0015\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9738 | Accuracy Std:   \t0.0189\n",
      "Recall Mean:     \t0.9889 | Recall Std:       \t0.0172\n",
      "Precision Mean:     \t0.9668 | Precision Std:   \t0.0265\n",
      "F1 Score Mean:     \t0.9775 | F1 Score Std:   \t0.0176\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9825\n",
      "Recall:     \t0.9873\n",
      "Precision:     \t0.9873\n",
      "F1 Score:     \t0.9873\n"
     ]
    }
   ],
   "source": [
    "# TO COMPARE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "do_cv_and_get_metrics(\n",
    "    classifier=LogisticRegression(), \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    scaler=StandardScaler(),\n",
    "    title='Sklearn Logistic Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8, random_seed=64825)\n",
    "\n",
    "cv_splits = kfolds_cross_validation(\n",
    "    data=X_train,\n",
    "    n_folds=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianDiscriminantAnalysis():\n",
    "    def __init__(self):        \n",
    "        pass\n",
    "\n",
    "    def calculate_sigma(self, X, mu):\n",
    "        n_features = X.shape[1]\n",
    "        n_rows = X.shape[0]\n",
    "        sigma=np.zeros((n_features, n_features))\n",
    "\n",
    "        for i in range(n_rows):\n",
    "            x_i = X[i,:].reshape(n_features, 1)\n",
    "            sigma += (x_i-mu) @ (x_i-mu).T\n",
    "\n",
    "        return sigma/(n_rows-1)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if len(y.shape)==1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        self.class_dict = {classes[i]: i for i in range(len(classes))}\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # n_classes\n",
    "        self.phi = np.zeros((len(classes), 1)) \n",
    "        # n_classes x n_features\n",
    "        self.mu = np.zeros((len(classes), n_features)) \n",
    "        # n_classes x n_features\n",
    "        self.sigma = np.zeros((len(classes), n_features, n_features)) \n",
    "\n",
    "        for label in classes:\n",
    "            \n",
    "            k = self.class_dict[label]\n",
    "\n",
    "            X_class = X[np.where(y==k)[0], :]\n",
    "            y_class = y[np.where(y==k)[0], :]\n",
    "            \n",
    "            self.phi[k] = len(y_class) / len(y)\n",
    "            self.mu[k] = np.mean(X_class, axis=0)\n",
    "            self.sigma[k] = self.calculate_sigma(X_class, self.mu[k].reshape(-1, 1))\n",
    "            # self.sigma[k] = np.cov(X_class.T)\n",
    "            \n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        classes = list(self.class_dict.keys())\n",
    "        prob_classes = np.zeros((X.shape[0], len(classes)))\n",
    "        for i, label in enumerate(classes):\n",
    "\n",
    "            k = self.class_dict[label]\n",
    "            sigma_det = np.linalg.det(self.sigma[k])\n",
    "            sigma_inv = np.linalg.pinv(self.sigma[k])\n",
    "            mu = self.mu[[k]]\n",
    "\n",
    "            first_part = -(1/2)*np.log(sigma_det)\n",
    "            second_part = -(1/2)*np.sum(((X-mu) @ sigma_inv) * (X-mu), axis=1)\n",
    "            third_part = np.log(self.phi[k])\n",
    "            \n",
    "            pred = first_part + second_part + third_part\n",
    "            prob_classes[:, i] = pred\n",
    "\n",
    "        preds = []\n",
    "        for i in range(prob_classes.shape[0]):\n",
    "            argmax = np.argmax(prob_classes[i, :])\n",
    "            preds.append(classes[argmax])\n",
    "            \n",
    "        return np.array(preds).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------My Gaussian Discriminant Analysis--------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9753 | Accuracy Std:   \t0.0023\n",
      "Recall Mean:     \t0.9920 | Recall Std:       \t0.0018\n",
      "Precision Mean:     \t0.9684 | Precision Std:   \t0.0034\n",
      "F1 Score Mean:     \t0.9800 | F1 Score Std:   \t0.0020\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9516 | Accuracy Std:   \t0.0213\n",
      "Recall Mean:     \t0.9636 | Recall Std:       \t0.0378\n",
      "Precision Mean:     \t0.9571 | Precision Std:   \t0.0308\n",
      "F1 Score Mean:     \t0.9595 | F1 Score Std:   \t0.0199\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9912\n",
      "Recall:     \t0.9873\n",
      "Precision:     \t1.0000\n",
      "F1 Score:     \t0.9936\n"
     ]
    }
   ],
   "source": [
    "do_cv_and_get_metrics(\n",
    "    classifier=MyGaussianDiscriminantAnalysis(), \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    title='My Gaussian Discriminant Analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------Sklearn - Gaussian Discriminant Analysis----------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9753 | Accuracy Std:   \t0.0023\n",
      "Recall Mean:     \t0.9920 | Recall Std:       \t0.0018\n",
      "Precision Mean:     \t0.9684 | Precision Std:   \t0.0034\n",
      "F1 Score Mean:     \t0.9800 | F1 Score Std:   \t0.0020\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9516 | Accuracy Std:   \t0.0213\n",
      "Recall Mean:     \t0.9636 | Recall Std:       \t0.0378\n",
      "Precision Mean:     \t0.9571 | Precision Std:   \t0.0308\n",
      "F1 Score Mean:     \t0.9595 | F1 Score Std:   \t0.0199\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9912\n",
      "Recall:     \t0.9873\n",
      "Precision:     \t1.0000\n",
      "F1 Score:     \t0.9936\n"
     ]
    }
   ],
   "source": [
    "# TO COMPARE\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "do_cv_and_get_metrics(\n",
    "    classifier=QuadraticDiscriminantAnalysis(), \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    title='Sklearn - Gaussian Discriminant Analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/breastcancer.csv', delimiter=',')\n",
    "print('Shape:', data.shape)\n",
    "data[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "y_train shape: (455, 1)\n",
      "X_test shape: (114, 30)\n",
      "y_test shape: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, 0.8, random_seed=64825)\n",
    "\n",
    "cv_splits = kfolds_cross_validation(\n",
    "    data=X_train,\n",
    "    n_folds=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNaiveBayes():\n",
    "    def __init__(self):        \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        \n",
    "        classes = np.unique(y)\n",
    "        self.class_to_idx_dict = {classes[i]: i for i in range(len(classes))}\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        self.prob_class = np.zeros((len(classes), 1)) # n_classes x 1\n",
    "        self.mu = np.zeros((len(classes), n_features)) # n_classes x n_features\n",
    "        self.std = np.zeros((len(classes), n_features)) # n_classes x n_features\n",
    "\n",
    "        for label in classes:\n",
    "\n",
    "            k = self.class_to_idx_dict[label]\n",
    "\n",
    "            X_class = X[np.where(y==label)[0], :]\n",
    "            y_class = y[np.where(y==label)[0], :]\n",
    "            \n",
    "            self.prob_class[k] = len(y_class) / len(y)\n",
    "            self.mu[k] = np.mean(X_class, axis=0)\n",
    "            self.std[k] = np.std(X_class, axis=0)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        idx_to_class = {v: k for k, v in self.class_to_idx_dict.items()}\n",
    "        prob_classes = np.zeros((X.shape[0], len(idx_to_class)))\n",
    "\n",
    "        for i, label in enumerate(idx_to_class.values()):\n",
    "\n",
    "            k = self.class_to_idx_dict[label]\n",
    "            mu = self.mu[[k]]\n",
    "            std = self.std[[k]]\n",
    "            prior = self.prob_class[k]\n",
    "\n",
    "            for idx, x in enumerate(X):\n",
    "\n",
    "                first_part = np.log(prior)\n",
    "                second_part = -(1/2) * np.sum(np.log(2*np.pi*(std**2)), axis=1)\n",
    "                third_part = -(1/2) * np.sum(((x - mu)**2)/(std**2), axis=1)\n",
    "                \n",
    "                pred = first_part + second_part + third_part\n",
    "                prob_classes[idx, i] = pred\n",
    "                \n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for i in range(prob_classes.shape[0]):\n",
    "            argmax = np.argmax(prob_classes[i, :])\n",
    "            preds.append(idx_to_class[argmax])\n",
    "            \n",
    "        return np.array(preds).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------My Gaussian Naive Bayes-------------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9355 | Accuracy Std:   \t0.0058\n",
      "Recall Mean:     \t0.9664 | Recall Std:       \t0.0065\n",
      "Precision Mean:     \t0.9307 | Precision Std:   \t0.0046\n",
      "F1 Score Mean:     \t0.9482 | F1 Score Std:   \t0.0046\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9275 | Accuracy Std:   \t0.0446\n",
      "Recall Mean:     \t0.9531 | Recall Std:       \t0.0574\n",
      "Precision Mean:     \t0.9295 | Precision Std:   \t0.0428\n",
      "F1 Score Mean:     \t0.9402 | F1 Score Std:   \t0.0408\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9649\n",
      "Recall:     \t0.9747\n",
      "Precision:     \t0.9747\n",
      "F1 Score:     \t0.9747\n"
     ]
    }
   ],
   "source": [
    "do_cv_and_get_metrics(\n",
    "    classifier=MyGaussianNaiveBayes(), \n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    title='My Gaussian Naive Bayes'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------Sklearn - Gaussian Naive Bayes---------------#\n",
      "\n",
      "--->\tTraining Metrics\n",
      "Accuracy Mean:     \t0.9355 | Accuracy Std:   \t0.0058\n",
      "Recall Mean:     \t0.9664 | Recall Std:       \t0.0065\n",
      "Precision Mean:     \t0.9307 | Precision Std:   \t0.0046\n",
      "F1 Score Mean:     \t0.9482 | F1 Score Std:   \t0.0046\n",
      "\n",
      "--->\tValidation Metrics\n",
      "Accuracy Mean:     \t0.9275 | Accuracy Std:   \t0.0446\n",
      "Recall Mean:     \t0.9531 | Recall Std:       \t0.0574\n",
      "Precision Mean:     \t0.9295 | Precision Std:   \t0.0428\n",
      "F1 Score Mean:     \t0.9402 | F1 Score Std:   \t0.0408\n",
      "\n",
      "--->\tTest Metrics\n",
      "Accuracy:     \t0.9649\n",
      "Recall:     \t0.9747\n",
      "Precision:     \t0.9747\n",
      "F1 Score:     \t0.9747\n"
     ]
    }
   ],
   "source": [
    "# TO COMPARE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "do_cv_and_get_metrics(\n",
    "    classifier=GaussianNB(var_smoothing=1e-13),\n",
    "    cv_splits=cv_splits, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    title='Sklearn - Gaussian Naive Bayes'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d84fc3ab72c8387ddb373470e784917d8b759f8763a65d23fac12a2e8075760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
